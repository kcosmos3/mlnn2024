{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks image recognition - MultiLayer Perceptron\n",
    "Use both MLNN for the following problem.\n",
    "\n",
    "1. Add random noise (see below on `size parameter` on [`np.random.normal`](https://numpy.org/doc/stable/reference/random/generated/numpy.random.normal.html)) to the images in training and testing. **Make sure each image gets a different noise feature added to it. Inspect by printing out several images. Note - the `size` parameter should match the data. **\n",
    "2. Compare the `accuracy` of train and val after N epochs for MLNN with and without noise. \n",
    "3. Vary the amount of noise by changing the `scale` parameter in `np.random.normal` by a factor. Use `.1, .5, 1.0, 2.0, 4.0` for the `scale` and keep track of the `accuracy` for training and validation and plot these results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `np.random.normal`\n",
    "\n",
    "## Parameters\n",
    "\n",
    "### loc\n",
    "\n",
    "Mean (“centre”) of the distribution.\n",
    "\n",
    "### scale\n",
    "\n",
    "Standard deviation (spread or “width”) of the distribution. Must be non-negative.\n",
    "\n",
    "### size\n",
    "\n",
    "Output shape. If the given shape is, e.g., (m, n, k), then m * n * k samples are drawn. If size is None (default), a single value is returned if loc and scale are both scalars. Otherwise, np.broadcast(loc, scale).size samples are drawn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks - Image Recognition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\kcosm\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Layer Neural Network\n",
    "Trains a simple deep NN on the MNIST dataset.\n",
    "Gets to 98.40% test accuracy after 20 epochs\n",
    "(there is *a lot* of margin for parameter tuning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Add noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noise is added here\n",
    "# The max value of the noise should not grossly surpass 1.0\n",
    "noise_train = np.random.normal(0.5, 0.05, (60000, 784))\n",
    "noise_test = np.random.normal(0.5, 0.05, (10000, 784))\n",
    "x_train2 = x_train + noise_train\n",
    "x_test2 = x_test + noise_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7830082232198076\n",
      "0.22467636179369982\n",
      "0.7592332878380708\n",
      "0.24213990810377145\n"
     ]
    }
   ],
   "source": [
    "print(np.max(noise_train))\n",
    "print(np.min(noise_train))\n",
    "print(np.max(noise_test))\n",
    "print(np.min(noise_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Compare Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-A. Accuracy without noise = 98.23%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\kcosm\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 669706 (2.55 MB)\n",
      "Trainable params: 669706 (2.55 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\Users\\kcosm\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:From C:\\Users\\kcosm\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\kcosm\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "469/469 [==============================] - 15s 23ms/step - loss: 0.2491 - accuracy: 0.9246 - val_loss: 0.1049 - val_accuracy: 0.9674\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 11s 22ms/step - loss: 0.1024 - accuracy: 0.9689 - val_loss: 0.0836 - val_accuracy: 0.9725\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.0725 - accuracy: 0.9774 - val_loss: 0.0749 - val_accuracy: 0.9771\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 11s 24ms/step - loss: 0.0567 - accuracy: 0.9822 - val_loss: 0.0689 - val_accuracy: 0.9784\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 11s 23ms/step - loss: 0.0440 - accuracy: 0.9852 - val_loss: 0.0661 - val_accuracy: 0.9806\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 11s 23ms/step - loss: 0.0375 - accuracy: 0.9879 - val_loss: 0.0673 - val_accuracy: 0.9811\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 11s 24ms/step - loss: 0.0350 - accuracy: 0.9885 - val_loss: 0.0817 - val_accuracy: 0.9781\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 11s 23ms/step - loss: 0.0291 - accuracy: 0.9902 - val_loss: 0.0677 - val_accuracy: 0.9820\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.0298 - accuracy: 0.9900 - val_loss: 0.0737 - val_accuracy: 0.9802\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.0258 - accuracy: 0.9910 - val_loss: 0.0688 - val_accuracy: 0.9836\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.0246 - accuracy: 0.9917 - val_loss: 0.0747 - val_accuracy: 0.9821\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.0224 - accuracy: 0.9925 - val_loss: 0.0671 - val_accuracy: 0.9839\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.0191 - accuracy: 0.9938 - val_loss: 0.0788 - val_accuracy: 0.9818\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 11s 23ms/step - loss: 0.0199 - accuracy: 0.9932 - val_loss: 0.0698 - val_accuracy: 0.9833\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 11s 23ms/step - loss: 0.0174 - accuracy: 0.9943 - val_loss: 0.0808 - val_accuracy: 0.9822\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.0189 - accuracy: 0.9938 - val_loss: 0.0719 - val_accuracy: 0.9835\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 11s 24ms/step - loss: 0.0157 - accuracy: 0.9946 - val_loss: 0.0877 - val_accuracy: 0.9825\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.0154 - accuracy: 0.9949 - val_loss: 0.0815 - val_accuracy: 0.9825\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.0174 - accuracy: 0.9941 - val_loss: 0.0828 - val_accuracy: 0.9836\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.0140 - accuracy: 0.9954 - val_loss: 0.0900 - val_accuracy: 0.9823\n",
      "Test loss: 0.09002116322517395\n",
      "Test accuracy: 0.9822999835014343\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=\"adam\",\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-B. Accuracy with noise = 97.93%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "469/469 [==============================] - 12s 24ms/step - loss: 0.2634 - accuracy: 0.9195 - val_loss: 0.1166 - val_accuracy: 0.9648\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.1521 - accuracy: 0.9517 - val_loss: 0.1021 - val_accuracy: 0.9677\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.1308 - accuracy: 0.9577 - val_loss: 0.0938 - val_accuracy: 0.9702\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.1170 - accuracy: 0.9624 - val_loss: 0.0937 - val_accuracy: 0.9719\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.1094 - accuracy: 0.9648 - val_loss: 0.0827 - val_accuracy: 0.9744\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.1025 - accuracy: 0.9668 - val_loss: 0.0832 - val_accuracy: 0.9745\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 9s 18ms/step - loss: 0.0997 - accuracy: 0.9673 - val_loss: 0.0937 - val_accuracy: 0.9713\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 9s 20ms/step - loss: 0.0981 - accuracy: 0.9677 - val_loss: 0.0867 - val_accuracy: 0.9724\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0927 - accuracy: 0.9698 - val_loss: 0.0812 - val_accuracy: 0.9747\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0931 - accuracy: 0.9696 - val_loss: 0.0718 - val_accuracy: 0.9800\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 10s 20ms/step - loss: 0.0876 - accuracy: 0.9712 - val_loss: 0.0778 - val_accuracy: 0.9766\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 9s 20ms/step - loss: 0.0943 - accuracy: 0.9695 - val_loss: 0.0799 - val_accuracy: 0.9773\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 9s 20ms/step - loss: 0.0836 - accuracy: 0.9725 - val_loss: 0.0769 - val_accuracy: 0.9755\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 9s 20ms/step - loss: 0.0846 - accuracy: 0.9725 - val_loss: 0.0959 - val_accuracy: 0.9694\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 9s 20ms/step - loss: 0.0842 - accuracy: 0.9721 - val_loss: 0.0839 - val_accuracy: 0.9735\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 9s 20ms/step - loss: 0.0797 - accuracy: 0.9738 - val_loss: 0.0678 - val_accuracy: 0.9795\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 10s 20ms/step - loss: 0.0736 - accuracy: 0.9747 - val_loss: 0.0704 - val_accuracy: 0.9781\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 10s 20ms/step - loss: 0.0768 - accuracy: 0.9746 - val_loss: 0.0703 - val_accuracy: 0.9793\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 9s 20ms/step - loss: 0.0747 - accuracy: 0.9751 - val_loss: 0.0751 - val_accuracy: 0.9763\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 0.0739 - accuracy: 0.9756 - val_loss: 0.0660 - val_accuracy: 0.9793\n",
      "Test loss: 0.06600886583328247\n",
      "Test accuracy: 0.9793000221252441\n"
     ]
    }
   ],
   "source": [
    "# With noise\n",
    "\n",
    "history2 = model.fit(x_train2, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test2, y_test))\n",
    "score2 = model.evaluate(x_test2, y_test, verbose=0)\n",
    "print('Test loss:', score2[0])\n",
    "print('Test accuracy:', score2[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result: Accuracy dropped by 0.30%p due to the noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Vary noises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "469/469 [==============================] - 15s 31ms/step - loss: 0.0895 - accuracy: 0.9705 - val_loss: 0.0724 - val_accuracy: 0.9790\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0831 - accuracy: 0.9725 - val_loss: 0.0710 - val_accuracy: 0.9783\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 9s 20ms/step - loss: 0.0799 - accuracy: 0.9736 - val_loss: 0.0833 - val_accuracy: 0.9751\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 9s 20ms/step - loss: 0.0773 - accuracy: 0.9744 - val_loss: 0.0678 - val_accuracy: 0.9804\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 10s 20ms/step - loss: 0.0771 - accuracy: 0.9744 - val_loss: 0.0796 - val_accuracy: 0.9778\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0694 - accuracy: 0.9771 - val_loss: 0.0729 - val_accuracy: 0.9782\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0731 - accuracy: 0.9755 - val_loss: 0.0737 - val_accuracy: 0.9782\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.0707 - accuracy: 0.9769 - val_loss: 0.0702 - val_accuracy: 0.9790\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.0720 - accuracy: 0.9762 - val_loss: 0.0867 - val_accuracy: 0.9756\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0674 - accuracy: 0.9778 - val_loss: 0.0717 - val_accuracy: 0.9790\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0684 - accuracy: 0.9777 - val_loss: 0.0837 - val_accuracy: 0.9765\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0656 - accuracy: 0.9785 - val_loss: 0.0719 - val_accuracy: 0.9784\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0643 - accuracy: 0.9780 - val_loss: 0.0789 - val_accuracy: 0.9782\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0637 - accuracy: 0.9784 - val_loss: 0.0662 - val_accuracy: 0.9798\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0675 - accuracy: 0.9776 - val_loss: 0.0807 - val_accuracy: 0.9766\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.0627 - accuracy: 0.9790 - val_loss: 0.0800 - val_accuracy: 0.9787\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.0617 - accuracy: 0.9801 - val_loss: 0.0746 - val_accuracy: 0.9778\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0606 - accuracy: 0.9798 - val_loss: 0.0674 - val_accuracy: 0.9797\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.0607 - accuracy: 0.9799 - val_loss: 0.0769 - val_accuracy: 0.9779\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 11s 23ms/step - loss: 0.0655 - accuracy: 0.9783 - val_loss: 0.0824 - val_accuracy: 0.9778\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 11s 22ms/step - loss: 0.4011 - accuracy: 0.8779 - val_loss: 0.2739 - val_accuracy: 0.9150\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.2777 - accuracy: 0.9105 - val_loss: 0.2408 - val_accuracy: 0.9266\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 9s 20ms/step - loss: 0.2319 - accuracy: 0.9235 - val_loss: 0.2331 - val_accuracy: 0.9275\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.2084 - accuracy: 0.9307 - val_loss: 0.2217 - val_accuracy: 0.9330\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 10s 20ms/step - loss: 0.1829 - accuracy: 0.9385 - val_loss: 0.2176 - val_accuracy: 0.9348\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 9s 20ms/step - loss: 0.1642 - accuracy: 0.9437 - val_loss: 0.2250 - val_accuracy: 0.9337\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 9s 20ms/step - loss: 0.1574 - accuracy: 0.9460 - val_loss: 0.2157 - val_accuracy: 0.9340\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 11s 23ms/step - loss: 0.1443 - accuracy: 0.9511 - val_loss: 0.2169 - val_accuracy: 0.9360\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 11s 22ms/step - loss: 0.1350 - accuracy: 0.9539 - val_loss: 0.2210 - val_accuracy: 0.9345\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.1297 - accuracy: 0.9564 - val_loss: 0.2331 - val_accuracy: 0.9327\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.1234 - accuracy: 0.9579 - val_loss: 0.2238 - val_accuracy: 0.9353\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.1159 - accuracy: 0.9602 - val_loss: 0.2323 - val_accuracy: 0.9351\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 9s 20ms/step - loss: 0.1112 - accuracy: 0.9624 - val_loss: 0.2407 - val_accuracy: 0.9332\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 9s 20ms/step - loss: 0.1051 - accuracy: 0.9640 - val_loss: 0.2398 - val_accuracy: 0.9333\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 8s 18ms/step - loss: 0.1051 - accuracy: 0.9647 - val_loss: 0.2461 - val_accuracy: 0.9346\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 9s 20ms/step - loss: 0.0946 - accuracy: 0.9679 - val_loss: 0.2548 - val_accuracy: 0.9316\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 0.0961 - accuracy: 0.9679 - val_loss: 0.2454 - val_accuracy: 0.9333\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 8s 18ms/step - loss: 0.0924 - accuracy: 0.9689 - val_loss: 0.2525 - val_accuracy: 0.9322\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 9s 18ms/step - loss: 0.0929 - accuracy: 0.9699 - val_loss: 0.2547 - val_accuracy: 0.9326\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 0.0894 - accuracy: 0.9706 - val_loss: 0.2652 - val_accuracy: 0.9320\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 11s 22ms/step - loss: 0.9846 - accuracy: 0.6960 - val_loss: 0.7318 - val_accuracy: 0.7607\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 0.7453 - accuracy: 0.7560 - val_loss: 0.6731 - val_accuracy: 0.7818\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 8s 18ms/step - loss: 0.6458 - accuracy: 0.7832 - val_loss: 0.6584 - val_accuracy: 0.7850\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 8s 18ms/step - loss: 0.5737 - accuracy: 0.8030 - val_loss: 0.6444 - val_accuracy: 0.7937\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 0.5170 - accuracy: 0.8213 - val_loss: 0.6490 - val_accuracy: 0.7856\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 0.4679 - accuracy: 0.8380 - val_loss: 0.6446 - val_accuracy: 0.7922\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 8s 17ms/step - loss: 0.4260 - accuracy: 0.8523 - val_loss: 0.6581 - val_accuracy: 0.7942\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 8s 18ms/step - loss: 0.3877 - accuracy: 0.8630 - val_loss: 0.6858 - val_accuracy: 0.7909\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 9s 18ms/step - loss: 0.3577 - accuracy: 0.8749 - val_loss: 0.6811 - val_accuracy: 0.7918\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 0.3243 - accuracy: 0.8878 - val_loss: 0.7319 - val_accuracy: 0.7920\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 9s 20ms/step - loss: 0.2969 - accuracy: 0.8961 - val_loss: 0.7563 - val_accuracy: 0.7889\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 0.2791 - accuracy: 0.9014 - val_loss: 0.7539 - val_accuracy: 0.7868\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 0.2564 - accuracy: 0.9110 - val_loss: 0.8223 - val_accuracy: 0.7869\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 8s 17ms/step - loss: 0.2431 - accuracy: 0.9161 - val_loss: 0.8174 - val_accuracy: 0.7857\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 8s 18ms/step - loss: 0.2338 - accuracy: 0.9195 - val_loss: 0.8288 - val_accuracy: 0.7858\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 8s 18ms/step - loss: 0.2167 - accuracy: 0.9255 - val_loss: 0.8496 - val_accuracy: 0.7865\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 8s 18ms/step - loss: 0.2090 - accuracy: 0.9276 - val_loss: 0.8974 - val_accuracy: 0.7828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20\n",
      "469/469 [==============================] - 8s 18ms/step - loss: 0.1985 - accuracy: 0.9319 - val_loss: 0.9381 - val_accuracy: 0.7816\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 8s 17ms/step - loss: 0.1887 - accuracy: 0.9361 - val_loss: 0.9372 - val_accuracy: 0.7787\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 9s 18ms/step - loss: 0.1811 - accuracy: 0.9387 - val_loss: 0.9556 - val_accuracy: 0.7794\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 10s 20ms/step - loss: 1.9382 - accuracy: 0.3638 - val_loss: 1.5751 - val_accuracy: 0.4667\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 1.6225 - accuracy: 0.4441 - val_loss: 1.5169 - val_accuracy: 0.4921\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 9s 20ms/step - loss: 1.5166 - accuracy: 0.4791 - val_loss: 1.4904 - val_accuracy: 0.5000\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 1.4156 - accuracy: 0.5105 - val_loss: 1.4955 - val_accuracy: 0.4989\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 1.3091 - accuracy: 0.5440 - val_loss: 1.5176 - val_accuracy: 0.4985\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 1.1986 - accuracy: 0.5783 - val_loss: 1.5405 - val_accuracy: 0.4911\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 1.0895 - accuracy: 0.6132 - val_loss: 1.5910 - val_accuracy: 0.4857\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 0.9793 - accuracy: 0.6518 - val_loss: 1.6789 - val_accuracy: 0.4785\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 9s 20ms/step - loss: 0.8842 - accuracy: 0.6844 - val_loss: 1.7418 - val_accuracy: 0.4717\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 10s 20ms/step - loss: 0.7961 - accuracy: 0.7171 - val_loss: 1.8418 - val_accuracy: 0.4634\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 0.7236 - accuracy: 0.7425 - val_loss: 1.9585 - val_accuracy: 0.4637\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 9s 20ms/step - loss: 0.6586 - accuracy: 0.7670 - val_loss: 2.0384 - val_accuracy: 0.4612\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 770s 2s/step - loss: 0.6044 - accuracy: 0.7859 - val_loss: 2.1263 - val_accuracy: 0.4583\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 12s 27ms/step - loss: 0.5554 - accuracy: 0.8050 - val_loss: 2.2598 - val_accuracy: 0.4555\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.5125 - accuracy: 0.8201 - val_loss: 2.3605 - val_accuracy: 0.4604\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 9s 20ms/step - loss: 0.4802 - accuracy: 0.8328 - val_loss: 2.4889 - val_accuracy: 0.4495\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.4524 - accuracy: 0.8433 - val_loss: 2.5190 - val_accuracy: 0.4526\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.4273 - accuracy: 0.8537 - val_loss: 2.6199 - val_accuracy: 0.4496\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.4034 - accuracy: 0.8631 - val_loss: 2.6518 - val_accuracy: 0.4455\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 9s 20ms/step - loss: 0.3879 - accuracy: 0.8680 - val_loss: 2.7092 - val_accuracy: 0.4478\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 2.6332 - accuracy: 0.1123 - val_loss: 2.2806 - val_accuracy: 0.1203\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 16s 34ms/step - loss: 2.2624 - accuracy: 0.1509 - val_loss: 2.2436 - val_accuracy: 0.1657\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 2.2153 - accuracy: 0.1842 - val_loss: 2.1929 - val_accuracy: 0.1983\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 13s 28ms/step - loss: 2.1627 - accuracy: 0.2090 - val_loss: 2.1689 - val_accuracy: 0.2085\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 12s 26ms/step - loss: 2.1138 - accuracy: 0.2282 - val_loss: 2.1585 - val_accuracy: 0.2172\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 13s 27ms/step - loss: 2.0622 - accuracy: 0.2510 - val_loss: 2.1606 - val_accuracy: 0.2229\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 13s 28ms/step - loss: 2.0078 - accuracy: 0.2703 - val_loss: 2.1675 - val_accuracy: 0.2237\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 13s 28ms/step - loss: 1.9434 - accuracy: 0.2930 - val_loss: 2.1854 - val_accuracy: 0.2254\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 12s 26ms/step - loss: 1.8821 - accuracy: 0.3144 - val_loss: 2.2100 - val_accuracy: 0.2209\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 1.8047 - accuracy: 0.3399 - val_loss: 2.2518 - val_accuracy: 0.2213\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 12s 26ms/step - loss: 1.7339 - accuracy: 0.3625 - val_loss: 2.2912 - val_accuracy: 0.2198\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 13s 27ms/step - loss: 1.6750 - accuracy: 0.3840 - val_loss: 2.3308 - val_accuracy: 0.2239\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 13s 27ms/step - loss: 1.6051 - accuracy: 0.4085 - val_loss: 2.3978 - val_accuracy: 0.2215\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 12s 27ms/step - loss: 1.5463 - accuracy: 0.4286 - val_loss: 2.4298 - val_accuracy: 0.2184\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 1.5017 - accuracy: 0.4459 - val_loss: 2.4685 - val_accuracy: 0.2191\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 1.4424 - accuracy: 0.4660 - val_loss: 2.5814 - val_accuracy: 0.2213\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 11s 24ms/step - loss: 1.4076 - accuracy: 0.4824 - val_loss: 2.5767 - val_accuracy: 0.2180\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 11s 24ms/step - loss: 1.3636 - accuracy: 0.4985 - val_loss: 2.6519 - val_accuracy: 0.2208\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 1.3176 - accuracy: 0.5145 - val_loss: 2.7180 - val_accuracy: 0.2188\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 13s 28ms/step - loss: 1.2872 - accuracy: 0.5273 - val_loss: 2.7432 - val_accuracy: 0.2259\n"
     ]
    }
   ],
   "source": [
    "accuracy_score = []\n",
    "noise_scale = [.1, .5, 1.0, 2.0, 4.0]\n",
    "\n",
    "#set for loop to see scores for each scale of noise\n",
    "for scale in noise_scale:\n",
    "    \n",
    "    noise_train = np.random.normal(0.5, scale, (60000, 784))\n",
    "    noise_test = np.random.normal(0.5, scale, (10000, 784))\n",
    "    x_train3 = x_train + noise_train\n",
    "    x_test3 = x_test + noise_test\n",
    "    \n",
    "    history3 = model.fit(x_train3, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test3, y_test))\n",
    "    \n",
    "    score3 = model.evaluate(x_test3, y_test, verbose=0)\n",
    "    accuracy = score3[1]\n",
    "    accuracy_score.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9778000116348267, 0.9319999814033508, 0.7793999910354614, 0.44780001044273376, 0.22589999437332153]\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGwCAYAAABVdURTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA1j0lEQVR4nO3de1yUdf7//+cAwhjK5CERkxA7KES2Aolg6paJYmuy26esz4baZmkfTVnbrcgt00+fpdqOuwUtrVmmKbcyrXbNnN08Lm0GYqa0dmKDdJAvWgPZCjRcvz/8MbedOMRwGubicb/drj/mzfua6/X23W3nudfhfVkMwzAEAABgEgG+LgAAAKAzEW4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpBPm6gO7W0NCgY8eOqX///rJYLL4uBwAAtIFhGKqpqdGwYcMUEND6uZleF26OHTumyMhIX5cBAADaoby8XMOHD2+1T68LN/3795d05h8nLCzMx9UAAIC2qK6uVmRkpPt3vDW9Ltw0XooKCwsj3AAA4GfackuJT28o3r17t2bOnKlhw4bJYrFoy5YtP7jPrl27lJCQIKvVqpEjR+rZZ5/t+kIBAIDf8Gm4OXXqlC699FI9/fTTbepfWlqqGTNmaOLEiSouLta9996rJUuWaNOmTV1cKQAA8Bc+vSyVlpamtLS0Nvd/9tlndd555+nJJ5+UJMXExKiwsFCPPvqorr322i6qEgAA+BO/Wufm3XffVWpqqkfbtGnTVFhYqPr6+mb3qa2tVXV1tccGAADMy6/CTUVFhcLDwz3awsPD9d1336mqqqrZfbKzs2Wz2dwbj4EDAGBufhVupKZ3SRuG0Wx7o6ysLDmdTvdWXl7e5TUCAADf8atHwYcOHaqKigqPtsrKSgUFBWnQoEHN7hMSEqKQkJDuKA8AAPQAfnXmJjk5WXa73aNt+/btSkxMVJ8+fXxUFQAA6El8Gm6++eYbHThwQAcOHJB05lHvAwcOqKysTNKZS0pz5sxx91+4cKG++OILLVu2TB999JGef/55rV69Wr/61a98UT4AAOiBfHpZqrCwUFdccYX787JlyyRJc+fO1QsvvCCHw+EOOpIUHR2trVu36pe//KWeeeYZDRs2TL///e97xGPgrgZD+0pPqrLmtIb0t2pc9EAFBvBiTgAAupvFaLwjt5eorq6WzWaT0+nstNcvbDvk0Mo3S+Rwnna3RdisWjEzVtPjIjrlGAAA9Gbe/H771T03PdG2Qw7dvm6/R7CRpArnad2+br+2HXL4qDIAAHonwk0HuBoMrXyzRM2d+mpsW/lmiVwNverkGAAAPkW46YB9pSebnLH5T4Ykh/O09pWe7L6iAADo5Qg3HVBZ03KwaU8/AADQcYSbDhjS39qp/QAAQMcRbjpgXPRARdisaumBb4vOPDU1Lnpgd5YFAECvRrjpgMAAi1bMjJWkJgGn8fOKmbGsdwMAQDci3HTQ9LgI5d4Ur6E2z0tPQ21W5d4Uzzo3AAB0M796cWZPNT0uQlNjh7JCMQAAPQDhppMEBliUfH7zbyYHAADdh8tSAADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVFjEr5dzNRisrAwAMBXCTS+27ZBDK98skcN52t0WYbNqxcxY3okFAPBbXJbqpbYdcuj2dfs9go0kVThP6/Z1+7XtkMNHlQEA0DGEm17I1WBo5ZslMpr5W2PbyjdL5GporgcAAD0b4aYX2ld6sskZm/9kSHI4T2tf6cnuKwoAgE5CuOmFKmtaDjbt6QcAQE9CuOmFhvS3dmo/AAB6EsJNLzQueqAibFa19MC3RWeemhoXPbA7ywIAoFMQbnqhwACLVsyMlaQmAafx84qZsax3AwDwS4SbXmp6XIRyb4rXUJvnpaehNqtyb4pnnRsAgN9iEb9ebHpchKbGDmWFYgCAqRBuernAAIuSzx/k6zIAAOg0XJYCAACmQrgBAACmQrgBAACmQrgBAACm4vNwk5OTo+joaFmtViUkJGjPnj2t9n/mmWcUExOjvn37atSoUVq7dm03VQoAAPyBT5+Wys/PV2ZmpnJycjRhwgT98Y9/VFpamkpKSnTeeec16Z+bm6usrCw999xzuuyyy7Rv3z7deuutGjBggGbOnOmDEQAAgJ7GYhiG4auDJyUlKT4+Xrm5ue62mJgYpaenKzs7u0n/lJQUTZgwQb/73e/cbZmZmSosLNTevXvbdMzq6mrZbDY5nU6FhYV1fBAAAKDLefP77bPLUnV1dSoqKlJqaqpHe2pqqgoKCprdp7a2Vlar54q6ffv21b59+1RfX9/iPtXV1R4bAAAwL5+Fm6qqKrlcLoWHh3u0h4eHq6Kiotl9pk2bpj/96U8qKiqSYRgqLCzU888/r/r6elVVVTW7T3Z2tmw2m3uLjIzs9LEAAICew+c3FFssnkv9G4bRpK3Rfffdp7S0NI0fP159+vTRrFmzNG/ePElSYGBgs/tkZWXJ6XS6t/Ly8k6tHwAA9Cw+CzeDBw9WYGBgk7M0lZWVTc7mNOrbt6+ef/55ffvtt/rXv/6lsrIyjRgxQv3799fgwYOb3SckJERhYWEeGwAAMC+fhZvg4GAlJCTIbrd7tNvtdqWkpLS6b58+fTR8+HAFBgZq48aN+slPfqKAAJ+fhAIAAD2ATx8FX7ZsmTIyMpSYmKjk5GTl5eWprKxMCxculHTmktLRo0fda9l8/PHH2rdvn5KSkvTVV1/p8ccf16FDh/Tiiy/6chgAAKAH8Wm4mT17tk6cOKFVq1bJ4XAoLi5OW7duVVRUlCTJ4XCorKzM3d/lcumxxx7TkSNH1KdPH11xxRUqKCjQiBEjfDQCAADQ0/h0nRtfYJ0bAAD8j1+scwMAANAVCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUfB5ucnJyFB0dLavVqoSEBO3Zs6fV/uvXr9ell16qs846SxEREbr55pt14sSJbqoWAAD0dD4NN/n5+crMzNTy5ctVXFysiRMnKi0tTWVlZc3237t3r+bMmaNbbrlFhw8f1iuvvKL3339f8+fP7+bKAQBAT+XTcPP444/rlltu0fz58xUTE6Mnn3xSkZGRys3Nbbb/P/7xD40YMUJLlixRdHS0Lr/8ci1YsECFhYUtHqO2tlbV1dUeGwAAMC+fhZu6ujoVFRUpNTXVoz01NVUFBQXN7pOSkqIvv/xSW7dulWEYOn78uF599VVdffXVLR4nOztbNpvNvUVGRnbqOAAAQM/is3BTVVUll8ul8PBwj/bw8HBVVFQ0u09KSorWr1+v2bNnKzg4WEOHDtXZZ5+tP/zhDy0eJysrS06n072Vl5d36jgAAEDP4vMbii0Wi8dnwzCatDUqKSnRkiVLdP/996uoqEjbtm1TaWmpFi5c2OL3h4SEKCwszGMDAADmFeSrAw8ePFiBgYFNztJUVlY2OZvTKDs7WxMmTNCvf/1rSdKYMWMUGhqqiRMn6sEHH1RERESX1w0AAHo2n525CQ4OVkJCgux2u0e73W5XSkpKs/t8++23CgjwLDkwMFDSmTM+AAAAPjtzI0nLli1TRkaGEhMTlZycrLy8PJWVlbkvM2VlZeno0aNau3atJGnmzJm69dZblZubq2nTpsnhcCgzM1Pjxo3TsGHDfDkU9HCuBkP7Sk+qsua0hvS3alz0QAUGNH/5EwDg33wabmbPnq0TJ05o1apVcjgciouL09atWxUVFSVJcjgcHmvezJs3TzU1NXr66ad155136uyzz9aVV16phx9+2FdDgB/YdsihlW+WyOE87W6LsFm1YmaspsdxKRMAzMZi9LLrOdXV1bLZbHI6ndxc3AtsO+TQ7ev26/v/kTees8m9KZ6AAwB+wJvfb58/LQV0FVeDoZVvljQJNpLcbSvfLJGroVflewAwPcINTGtf6UmPS1HfZ0hyOE9rX+nJ7isKANDlCDcwrcqaloNNe/oBAPwD4QamNaS/tVP7AQD8A+EGpjUueqAibFa19MC3RWeemhoXPbA7ywIAdDHCDUwrMMCiFTNjJalJwGn8vGJmLOvdAIDJEG5gatPjIpR7U7yG2jwvPQ21WXkMHABMyqeL+AHdYXpchKbGDmWFYgDoJQg36BUCAyxKPn+Qr8sAAHQDLksBAABTIdwAAABTIdwAAABTIdwAAABTIdwAAABTIdwAAABTIdwAAABTIdwAAABTIdwAAABTIdwAAABTIdwAAABTIdwAAABTIdwAAABTIdwAAABTIdwAAABTIdwAAABTIdwAAABTIdwAAABTIdwAAABTIdwAAABTIdwAAABTIdwAAABTIdwAAABTIdwAAABT8Xm4ycnJUXR0tKxWqxISErRnz54W+86bN08Wi6XJdvHFF3djxQAAoCfzabjJz89XZmamli9fruLiYk2cOFFpaWkqKytrtv9TTz0lh8Ph3srLyzVw4EBdd9113Vw5AADoqSyGYRi+OnhSUpLi4+OVm5vrbouJiVF6erqys7N/cP8tW7boZz/7mUpLSxUVFdWmY1ZXV8tms8npdCosLKzdtQMAgO7jze+3z87c1NXVqaioSKmpqR7tqampKigoaNN3rF69WldddVWrwaa2tlbV1dUeGwAAMC+fhZuqqiq5XC6Fh4d7tIeHh6uiouIH93c4HHrrrbc0f/78VvtlZ2fLZrO5t8jIyA7VDQAAejaf31BssVg8PhuG0aStOS+88ILOPvtspaent9ovKytLTqfTvZWXl3ekXAAA0MMF+erAgwcPVmBgYJOzNJWVlU3O5nyfYRh6/vnnlZGRoeDg4Fb7hoSEKCQkpMP1AgAA/+CzMzfBwcFKSEiQ3W73aLfb7UpJSWl13127dunTTz/VLbfc0pUlAgAAP+SzMzeStGzZMmVkZCgxMVHJycnKy8tTWVmZFi5cKOnMJaWjR49q7dq1HvutXr1aSUlJiouL80XZAACgB/NpuJk9e7ZOnDihVatWyeFwKC4uTlu3bnU//eRwOJqseeN0OrVp0yY99dRTvigZAAD0cD5d58YXWOcGAAD/4xfr3AAAAHQFwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVr8PNiBEjtGrVqiavRQAAAOgJvA43d955p15//XWNHDlSU6dO1caNG1VbW9sVtQEAAHjN63Bzxx13qKioSEVFRYqNjdWSJUsUERGhxYsXa//+/V1RIwAAQJt1+MWZ9fX1ysnJ0d133636+nrFxcVp6dKluvnmm2WxWDqrzk7DizMBAPA/3vx+B7X3IPX19dq8ebPWrFkju92u8ePH65ZbbtGxY8e0fPly/fWvf9XLL7/c3q8HAABoF6/Dzf79+7VmzRpt2LBBgYGBysjI0BNPPKHRo0e7+6SmpmrSpEmdWigAAEBbeB1uLrvsMk2dOlW5ublKT09Xnz59mvSJjY3VDTfc0CkFAgAAeMPrcPP5558rKiqq1T6hoaFas2ZNu4sCAABoL6+flqqsrNR7773XpP29995TYWFhpxQFAADQXl6Hm0WLFqm8vLxJ+9GjR7Vo0aJOKQoAAKC9vA43JSUlio+Pb9I+duxYlZSUdEpRAAAA7eV1uAkJCdHx48ebtDscDgUFtfvJcgAAgE7hdbiZOnWqsrKy5HQ63W1ff/217r33Xk2dOrVTiwMAAPCW16daHnvsMU2aNElRUVEaO3asJOnAgQMKDw/XSy+91OkFAgAAeMPrcHPuuefq4MGDWr9+vT744AP17dtXN998s2688cZm17wBAADoTu26SSY0NFS33XZbZ9cCAADQYe2+A7ikpERlZWWqq6vzaL/mmms6XBQAAEB7tWuF4p/+9Kf68MMPZbFY1PhS8cY3gLtcrs6tEAAAwAtePy21dOlSRUdH6/jx4zrrrLN0+PBh7d69W4mJidq5c2cXlAgAANB2Xp+5effdd/XOO+/onHPOUUBAgAICAnT55ZcrOztbS5YsUXFxcVfUCQAA0CZen7lxuVzq16+fJGnw4ME6duyYJCkqKkpHjhzp3OoAAAC85PWZm7i4OB08eFAjR45UUlKSHnnkEQUHBysvL08jR47sihoBAADazOtw85vf/EanTp2SJD344IP6yU9+ookTJ2rQoEHKz8/v9AIBAAC8YTEaH3fqgJMnT2rAgAHuJ6Z6surqatlsNjmdToWFhfm6HAAA0Abe/H57dc/Nd999p6CgIB06dMijfeDAgX4RbAAAgPl5FW6CgoIUFRXVqWvZ5OTkKDo6WlarVQkJCdqzZ0+r/Wtra7V8+XJFRUUpJCRE559/vp5//vlOqwcAAPg3r5+W+s1vfqOsrCydPHmywwfPz89XZmamli9fruLiYk2cOFFpaWkqKytrcZ/rr79ef/vb37R69WodOXJEGzZs0OjRoztcCwAAMAev77kZO3asPv30U9XX1ysqKkqhoaEef9+/f3+bvyspKUnx8fHKzc11t8XExCg9PV3Z2dlN+m/btk033HCDPv/8cw0cONCbst245wYAAP/jze+3109Lpaent7cuD3V1dSoqKtI999zj0Z6amqqCgoJm93njjTeUmJioRx55RC+99JJCQ0N1zTXX6H//93/Vt2/fZvepra1VbW2t+3N1dXWn1A8AAHomr8PNihUrOuXAVVVVcrlcCg8P92gPDw9XRUVFs/t8/vnn2rt3r6xWqzZv3qyqqir9z//8j06ePNnifTfZ2dlauXJlp9QMAAB6Pq/vuels33/KyjCMFp+8amhokMVi0fr16zVu3DjNmDFDjz/+uF544QX9+9//bnafrKwsOZ1O91ZeXt7pYwAAAD2H12duAgICWn3su61PUg0ePFiBgYFNztJUVlY2OZvTKCIiQueee65sNpu7LSYmRoZh6Msvv9SFF17YZJ+QkBCFhIS0qSYAAOD/vA43mzdv9vhcX1+v4uJivfjii15d/gkODlZCQoLsdrt++tOfutvtdrtmzZrV7D4TJkzQK6+8om+++cb9fquPP/5YAQEBGj58uLdDAQAAJtQpKxRL0ssvv6z8/Hy9/vrrbd4nPz9fGRkZevbZZ5WcnKy8vDw999xzOnz4sKKiopSVlaWjR49q7dq1kqRvvvlGMTExGj9+vFauXKmqqirNnz9fkydP1nPPPdemY/K0FAAA/qdLn5ZqSVJSkm699Vav9pk9e7ZOnDihVatWyeFwKC4uTlu3blVUVJQkyeFweKx5069fP9ntdt1xxx1KTEzUoEGDdP311+vBBx/srGEAAAA/1ylnbv79738rKytLb731lo4cOdIZdXUZztwAAOB/uvTMzfdfkGkYhmpqanTWWWdp3bp13lcLAADQibwON0888YRHuAkICNA555yjpKQkDRgwoFOLAwAA8JbX4WbevHldUAYAAEDn8HoRvzVr1uiVV15p0v7KK6/oxRdf7JSiAAAA2svrcPPQQw9p8ODBTdqHDBmi3/72t51SFAAAQHt5HW6++OILRUdHN2mPioryeGwbAADAF7wON0OGDNHBgwebtH/wwQcaNGhQpxQFAADQXl6HmxtuuEFLlizRjh075HK55HK59M4772jp0qW64YYbuqJGAACANvP6aakHH3xQX3zxhaZMmaKgoDO7NzQ0aM6cOdxzAwAAfK7dKxR/8sknOnDggPr27atLLrnE/cqEno4VigEA8D/d8m6pCy+8UBdeeGF7dwcAAOgSXt9z81//9V966KGHmrT/7ne/03XXXdcpRQEAALSX1+Fm165duvrqq5u0T58+Xbt37+6UogAAANrL63DzzTffKDg4uEl7nz59VF1d3SlFAQAAtJfX4SYuLk75+flN2jdu3KjY2NhOKQoAAKC9vL6h+L777tO1116rzz77TFdeeaUk6W9/+5tefvllvfrqq51eIAAAgDe8DjfXXHONtmzZot/+9rd69dVX1bdvX1166aV65513eLQaAAD4XLvXuWn09ddfa/369Vq9erU++OADuVyuzqqtS7DODQAA/seb32+v77lp9M477+imm27SsGHD9PTTT2vGjBkqLCxs79cBAAB0Cq8uS3355Zd64YUX9Pzzz+vUqVO6/vrrVV9fr02bNnEzMQAA6BHafOZmxowZio2NVUlJif7whz/o2LFj+sMf/tCVtQEAAHitzWdutm/friVLluj222/ntQsAAKDHavOZmz179qimpkaJiYlKSkrS008/rf/3//5fV9YGAADgtTaHm+TkZD333HNyOBxasGCBNm7cqHPPPVcNDQ2y2+2qqanpyjoBAADapEOPgh85ckSrV6/WSy+9pK+//lpTp07VG2+80Zn1dToeBQcAwP90y6PgkjRq1Cg98sgj+vLLL7Vhw4aOfBUAAECn6PAifv6GMzcAAPifbjtzAwAA0NMQbgAAgKkQbgAAgKkQbgAAgKkQbgAAgKkQbgAAgKkQbgAAgKn4PNzk5OQoOjpaVqtVCQkJ2rNnT4t9d+7cKYvF0mT75z//2Y0VAwCAnsyn4SY/P1+ZmZlavny5iouLNXHiRKWlpamsrKzV/Y4cOSKHw+HeeEs5AABo5NMVipOSkhQfH6/c3Fx3W0xMjNLT05Wdnd2k/86dO3XFFVfoq6++0tlnn92mY9TW1qq2ttb9ubq6WpGRkaxQDACAH/GLFYrr6upUVFSk1NRUj/bU1FQVFBS0uu/YsWMVERGhKVOmaMeOHa32zc7Ols1mc2+RkZEdrh0AAPRcPgs3VVVVcrlcCg8P92gPDw9XRUVFs/tEREQoLy9PmzZt0muvvaZRo0ZpypQp2r17d4vHycrKktPpdG/l5eWdOg4AANCzBPm6AIvF4vHZMIwmbY1GjRqlUaNGuT8nJyervLxcjz76qCZNmtTsPiEhIQoJCem8ggEAQI/mszM3gwcPVmBgYJOzNJWVlU3O5rRm/Pjx+uSTTzq7PAAA4Kd8Fm6Cg4OVkJAgu93u0W6325WSktLm7ykuLlZERERnlwcAAPyUTy9LLVu2TBkZGUpMTFRycrLy8vJUVlamhQsXSjpzv8zRo0e1du1aSdKTTz6pESNG6OKLL1ZdXZ3WrVunTZs2adOmTb4cBgAA6EF8Gm5mz56tEydOaNWqVXI4HIqLi9PWrVsVFRUlSXI4HB5r3tTV1elXv/qVjh49qr59++riiy/WX/7yF82YMcNXQwAAAD2MT9e58QVvnpMHAAA9g1+scwMAANAVCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUfPriTABoD1eDoX2lJ1VZc1pD+ls1LnqgAgMsvi4LQA9BuAHgV7YdcmjlmyVyOE+72yJsVq2YGavpcRE+rAxAT8FlKQB+Y9shh25ft98j2EhShfO0bl+3X9sOOXxUGYCehHADwC+4GgytfLNERjN/a2xb+WaJXA3N9QDQmxBuAPiFfaUnm5yx+U+GJIfztPaVnuy+ogD0SIQbAH6hsqblYNOefgDMi3ADwC8M6W/t1H4AzItwA8AvjIseqAibVS098G3RmaemxkUP7M6yAPRAhBsAfiEwwKIVM2MlqUnAafy8YmYs690AINwA8B/T4yKUe1O8hto8Lz0NtVmVe1M869wAkMQifgD8zPS4CE2NHcoKxQBaRLgB4HcCAyxKPn+Qr8sA0ENxWQoAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJiKz8NNTk6OoqOjZbValZCQoD179rRpv7///e8KCgrSj370o64tEAAA+BWfhpv8/HxlZmZq+fLlKi4u1sSJE5WWlqaysrJW93M6nZozZ46mTJnSTZUCAAB/YTEMw/DVwZOSkhQfH6/c3Fx3W0xMjNLT05Wdnd3ifjfccIMuvPBCBQYGasuWLTpw4ECLfWtra1VbW+v+XF1drcjISDmdToWFhXXKOAAAQNeqrq6WzWZr0++3z87c1NXVqaioSKmpqR7tqampKigoaHG/NWvW6LPPPtOKFSvadJzs7GzZbDb3FhkZ2aG6AQBAz+azcFNVVSWXy6Xw8HCP9vDwcFVUVDS7zyeffKJ77rlH69evV1BQUJuOk5WVJafT6d7Ky8s7XDsAAOi52pYQupDFYvH4bBhGkzZJcrlc+u///m+tXLlSF110UZu/PyQkRCEhIR2uEwAA+AefhZvBgwcrMDCwyVmaysrKJmdzJKmmpkaFhYUqLi7W4sWLJUkNDQ0yDENBQUHavn27rrzyym6pHQAA9Fw+uywVHByshIQE2e12j3a73a6UlJQm/cPCwvThhx/qwIED7m3hwoUaNWqUDhw4oKSkpO4qHQAA9GA+vSy1bNkyZWRkKDExUcnJycrLy1NZWZkWLlwo6cz9MkePHtXatWsVEBCguLg4j/2HDBkiq9XapB0AAPRePg03s2fP1okTJ7Rq1So5HA7FxcVp69atioqKkiQ5HI4fXPMGAADgP/l0nRtf8OY5eQAA0DP4xTo3AAAAXYFwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATMXn4SYnJ0fR0dGyWq1KSEjQnj17Wuy7d+9eTZgwQYMGDVLfvn01evRoPfHEE91YLQAA6OmCfHnw/Px8ZWZmKicnRxMmTNAf//hHpaWlqaSkROedd16T/qGhoVq8eLHGjBmj0NBQ7d27VwsWLFBoaKhuu+02H4wAAAD0NBbDMAxfHTwpKUnx8fHKzc11t8XExCg9PV3Z2dlt+o6f/exnCg0N1UsvvdSm/tXV1bLZbHI6nQoLC2tX3QAAoHt58/vts8tSdXV1KioqUmpqqkd7amqqCgoK2vQdxcXFKigo0OTJk1vsU1tbq+rqao8NAACYl8/CTVVVlVwul8LDwz3aw8PDVVFR0eq+w4cPV0hIiBITE7Vo0SLNnz+/xb7Z2dmy2WzuLTIyslPqBwAAPZPPbyi2WCwenw3DaNL2fXv27FFhYaGeffZZPfnkk9qwYUOLfbOysuR0Ot1beXl5p9QNAAB6Jp/dUDx48GAFBgY2OUtTWVnZ5GzO90VHR0uSLrnkEh0/flwPPPCAbrzxxmb7hoSEKCQkpHOKBgAAPZ7PztwEBwcrISFBdrvdo91utyslJaXN32MYhmprazu7PAAA4Kd8+ij4smXLlJGRocTERCUnJysvL09lZWVauHChpDOXlI4ePaq1a9dKkp555hmdd955Gj16tKQz6948+uijuuOOO3w2BgAA0LP4NNzMnj1bJ06c0KpVq+RwOBQXF6etW7cqKipKkuRwOFRWVubu39DQoKysLJWWliooKEjnn3++HnroIS1YsMBXQwAAAD2MT9e58QXWuQEAwP/4xTo3AAAAXYFwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATCXI1wUAAABzcDUY2ld6UpU1pzWkv1XjogcqMMDS7XUQbgAAQIdtO+TQyjdL5HCedrdF2KxaMTNW0+MiurUWLksBAIAO2XbIodvX7fcINpJU4Tyt29ft17ZDjm6th3ADAADazdVgaOWbJTKa+Vtj28o3S+RqaK5H1yDcAACAdttXerLJGZv/ZEhyOE9rX+nJbquJcAMAANqtsqblYNOefp2BcAMAANptSH9rp/brDIQbAADQbuOiByrCZlVLD3xbdOapqXHRA7utJsINAABot8AAi1bMjJWkJgGn8fOKmbHdut4N4QYAAHTI9LgI5d4Ur6E2z0tPQ21W5d4U3+3r3LCIHwAA6LDpcRGaGjuUFYoBAIB5BAZYlHz+IF+XwWUpAABgLj4PNzk5OYqOjpbValVCQoL27NnTYt/XXntNU6dO1TnnnKOwsDAlJyfr7bff7sZqAQBAT+fTcJOfn6/MzEwtX75cxcXFmjhxotLS0lRWVtZs/927d2vq1KnaunWrioqKdMUVV2jmzJkqLi7u5soBAEBPZTEMo/te9vA9SUlJio+PV25urrstJiZG6enpys7ObtN3XHzxxZo9e7buv//+Zv9eW1ur2tpa9+fq6mpFRkbK6XQqLCysYwMAAADdorq6WjabrU2/3z47c1NXV6eioiKlpqZ6tKempqqgoKBN39HQ0KCamhoNHNjywkDZ2dmy2WzuLTIyskN1AwCAns1n4aaqqkoul0vh4eEe7eHh4aqoqGjTdzz22GM6deqUrr/++hb7ZGVlyel0urfy8vIO1Q0AAHo2nz8KbrF4Pv9uGEaTtuZs2LBBDzzwgF5//XUNGTKkxX4hISEKCQnpcJ0AAMA/+CzcDB48WIGBgU3O0lRWVjY5m/N9+fn5uuWWW/TKK6/oqquu6soyAQCAn/HZZang4GAlJCTIbrd7tNvtdqWkpLS434YNGzRv3jy9/PLLuvrqq7u6TAAA4Gd8ellq2bJlysjIUGJiopKTk5WXl6eysjItXLhQ0pn7ZY4ePaq1a9dKOhNs5syZo6eeekrjx493n/Xp27evbDZbm47Z+HBYdXV1F4wIAAB0hcbf7TY95G342DPPPGNERUUZwcHBRnx8vLFr1y733+bOnWtMnjzZ/Xny5MmGpCbb3Llz23y88vLyZr+DjY2NjY2Nredv5eXlP/hb79N1bnyhoaFBx44dU//+/X/wxuXGNXHKy8tNvSYO4zQXxmkevWGMEuM0m64ap2EYqqmp0bBhwxQQ0PpdNT5/Wqq7BQQEaPjw4V7tExYWZur/EBsxTnNhnObRG8YoMU6z6YpxtvUWFJ+/WwoAAKAzEW4AAICpEG5aERISohUrVph+EUDGaS6M0zx6wxglxmk2PWGcve6GYgAAYG6cuQEAAKZCuAEAAKZCuAEAAKZCuAEAAKbS68NNTk6OoqOjZbValZCQoD179rTaf9euXUpISJDVatXIkSP17LPPdlOlHePNOHfu3CmLxdJk++c//9mNFXtv9+7dmjlzpoYNGyaLxaItW7b84D7+Np/ejtFf5zI7O1uXXXaZ+vfvryFDhig9PV1Hjhz5wf38aT7bM0Z/nM/c3FyNGTPGvaBbcnKy3nrrrVb38ad5bOTtOP1xLr8vOztbFotFmZmZrfbzxXz26nCTn5+vzMxMLV++XMXFxZo4caLS0tJUVlbWbP/S0lLNmDFDEydOVHFxse69914tWbJEmzZt6ubKvePtOBsdOXJEDofDvV144YXdVHH7nDp1SpdeeqmefvrpNvX3x/n0doyN/G0ud+3apUWLFukf//iH7Ha7vvvuO6WmpurUqVMt7uNv89meMTbyp/kcPny4HnroIRUWFqqwsFBXXnmlZs2apcOHDzfb39/msZG342zkT3P5n95//33l5eVpzJgxrfbz2Xy2+Y2TJjRu3Dhj4cKFHm2jR4827rnnnmb733XXXcbo0aM92hYsWGCMHz++y2rsDN6Oc8eOHYYk46uvvuqG6rqGJGPz5s2t9vHX+WzUljGaYS4NwzAqKysNSR4v1v0+f5/PtozRLPM5YMAA409/+lOzf/P3efxPrY3Tn+eypqbGuPDCCw273W5MnjzZWLp0aYt9fTWfvfbMTV1dnYqKipSamurRnpqaqoKCgmb3effdd5v0nzZtmgoLC1VfX99ltXZEe8bZaOzYsYqIiNCUKVO0Y8eOrizTJ/xxPtvL3+fS6XRKkgYOHNhiH3+fz7aMsZG/zqfL5dLGjRt16tQpJScnN9vH3+dRats4G/njXC5atEhXX321rrrqqh/s66v57LXhpqqqSi6XS+Hh4R7t4eHhqqioaHafioqKZvt/9913qqqq6rJaO6I944yIiFBeXp42bdqk1157TaNGjdKUKVO0e/fu7ii52/jjfHrLDHNpGIaWLVumyy+/XHFxcS328+f5bOsY/XU+P/zwQ/Xr108hISFauHChNm/erNjY2Gb7+vM8ejNOf53LjRs3av/+/crOzm5Tf1/NZ697K/j3WSwWj8+GYTRp+6H+zbX3NN6Mc9SoURo1apT7c3JyssrLy/Xoo49q0qRJXVpnd/PX+WwrM8zl4sWLdfDgQe3du/cH+/rrfLZ1jP46n6NGjdKBAwf09ddfa9OmTZo7d6527drV4g+/v86jN+P0x7ksLy/X0qVLtX37dlmt1jbv54v57LVnbgYPHqzAwMAmZy8qKyubpMxGQ4cObbZ/UFCQBg0a1GW1dkR7xtmc8ePH65NPPuns8nzKH+ezM/jTXN5xxx164403tGPHDg0fPrzVvv46n96MsTn+MJ/BwcG64IILlJiYqOzsbF166aV66qmnmu3rr/MoeTfO5vT0uSwqKlJlZaUSEhIUFBSkoKAg7dq1S7///e8VFBQkl8vVZB9fzWevDTfBwcFKSEiQ3W73aLfb7UpJSWl2n+Tk5Cb9t2/frsTERPXp06fLau2I9oyzOcXFxYqIiOjs8nzKH+ezM/jDXBqGocWLF+u1117TO++8o+jo6B/cx9/msz1jbI4/zOf3GYah2traZv/mb/PYmtbG2ZyePpdTpkzRhx9+qAMHDri3xMRE/fznP9eBAwcUGBjYZB+fzWeX3q7cw23cuNHo06ePsXr1aqOkpMTIzMw0QkNDjX/961+GYRjGPffcY2RkZLj7f/7558ZZZ51l/PKXvzRKSkqM1atXG3369DFeffVVXw2hTbwd5xNPPGFs3rzZ+Pjjj41Dhw4Z99xzjyHJ2LRpk6+G0CY1NTVGcXGxUVxcbEgyHn/8caO4uNj44osvDMMwx3x6O0Z/ncvbb7/dsNlsxs6dOw2Hw+Hevv32W3cff5/P9ozRH+czKyvL2L17t1FaWmocPHjQuPfee42AgABj+/bthmH4/zw28nac/jiXzfn+01I9ZT57dbgxDMN45plnjKioKCM4ONiIj4/3eAxz7ty5xuTJkz3679y50xg7dqwRHBxsjBgxwsjNze3mitvHm3E+/PDDxvnnn29YrVZjwIABxuWXX2785S9/8UHV3ml8tPL729y5cw3DMMd8ejtGf53L5sYoyVizZo27j7/PZ3vG6I/z+Ytf/ML9vz3nnHOOMWXKFPcPvmH4/zw28nac/jiXzfl+uOkp82kxjP//zh4AAAAT6LX33AAAAHMi3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3ADodj/+8Y+VmZnZ5cfJy8tTZGSkAgIC9OSTT3bpsXbu3CmLxaKvv/66S48D4IcRbgB4qKys1IIFC3TeeecpJCREQ4cO1bRp0/Tuu+/6ujSvVFdXa/Hixbr77rt19OhR3Xbbbc32s1gsslqt+uKLLzza09PTNW/evDYfLyUlRQ6HQzabrSNlA+gEQb4uAEDPcu2116q+vl4vvviiRo4cqePHj+tvf/ubTp486evSvFJWVqb6+npdffXVP/imZYvFovvvv18vvvhiu48XHBysoUOHtnt/AJ2HMzcA3L7++mvt3btXDz/8sK644gpFRUVp3LhxysrK0tVXX+3R77bbblN4eLisVqvi4uL05z//WZJ04sQJ3XjjjRo+fLjOOussXXLJJdqwYUOrx62rq9Ndd92lc889V6GhoUpKStLOnTtb3aesrEyzZs1Sv379FBYWpuuvv17Hjx+XJL3wwgu65JJLJEkjR46UxWLRv/71rxa/64477tC6dev04YcfttintrZWS5Ys0ZAhQ2S1WnX55Zfr/fffd//9+5elvvjiC82cOVMDBgxQaGioLr74Ym3dutXdv6SkRDNmzFC/fv0UHh6ujIwMVVVVtTpmAG1DuAHg1q9fP/Xr109btmxRbW1ts30aGhqUlpamgoICrVu3TiUlJXrooYcUGBgoSTp9+rQSEhL05z//WYcOHdJtt92mjIwMvffeey0e9+abb9bf//53bdy4UQcPHtR1112n6dOn65NPPmm2v2EYSk9P18mTJ7Vr1y7Z7XZ99tlnmj17tiRp9uzZ+utf/ypJ2rdvnxwOhyIjI1s8fkpKin7yk58oKyurxT533XWXNm3apBdffFH79+/XBRdcoGnTprV4RmvRokWqra3V7t279eGHH+rhhx9Wv379JEkOh0OTJ0/Wj370IxUWFmrbtm06fvy4rr/++haPD8ALXf7ecQB+5dVXXzUGDBhgWK1WIyUlxcjKyjI++OAD99/ffvttIyAgwDhy5Eibv3PGjBnGnXfe6f48efJkY+nSpYZhGMann35qWCwW4+jRox77TJkyxcjKymr2+7Zv324EBgYaZWVl7rbDhw8bkox9+/YZhmEYxcXFhiSjtLS01dokGZs3bzYOHz5sBAYGGrt37zYMwzBmzZplzJ071zAMw/jmm2+MPn36GOvXr3fvV1dXZwwbNsx45JFHDMMwjB07dhiSjK+++sowDMO45JJLjAceeKDZY953331GamqqR1t5ebkhyat/VwDN48wNAA/XXnutjh07pjfeeEPTpk3Tzp07FR8frxdeeEGSdODAAQ0fPlwXXXRRs/u7XC793//9n8aMGaNBgwapX79+2r59u8rKyprtv3//fhmGoYsuush95qhfv37atWuXPvvss2b3+eijjxQZGelxNiY2NlZnn322Pvroo3aNOzY2VnPmzNHdd9/d5G+fffaZ6uvrNWHCBHdbnz59NG7cuBaPt2TJEj344IOaMGGCVqxYoYMHD7r/VlRUpB07dniMd/To0e5jAegYbigG0ITVatXUqVM1depU3X///Zo/f75WrFihefPmqW/fvq3u+9hjj+mJJ57Qk08+qUsuuUShoaHKzMxUXV1ds/0bGhoUGBiooqIi96WtRo2Xcb7PMAxZLJY2t7fVypUrddFFF2nLli1NvldSk+9u7Xjz58/XtGnT9Je//EXbt29Xdna2HnvsMd1xxx1qaGjQzJkz9fDDDzfZ74dufgbwwzhzA+AHxcbG6tSpU5KkMWPG6Msvv9THH3/cbN89e/Zo1qxZuummm3TppZdq5MiRLd47I0ljx46Vy+VSZWWlLrjgAo+tpaePYmNjVVZWpvLycndbSUmJnE6nYmJi2j3OyMhILV68WPfee69cLpe7/YILLlBwcLD27t3rbquvr1dhYWGrx4uMjNTChQv12muv6c4779Rzzz0nSYqPj9fhw4c1YsSIJmMODQ1td/0AziDcAHA7ceKErrzySq1bt04HDx5UaWmpXnnlFT3yyCOaNWuWJGny5MmaNGmSrr32WtntdpWWluqtt97Stm3bJJ0JAna7XQUFBfroo4+0YMECVVRUtHjMiy66SD//+c81Z84cvfbaayotLdX777+vhx9+2OPpov901VVXacyYMfr5z3+u/fv3a9++fZozZ44mT56sxMTEDv0bZGVl6dixY+4bkiUpNDRUt99+u379619r27ZtKikp0a233qpvv/1Wt9xyS7Pfk5mZqbffflulpaXav3+/3nnnHXcQWrRokU6ePKkbb7xR+/bt0+eff67t27frF7/4hUeoAtA+hBsAbv369VNSUpKeeOIJTZo0SXFxcbrvvvt066236umnn3b327Rpky677DLdeOONio2N1V133eX+Ub7vvvsUHx+vadOm6cc//rGGDh2q9PT0Vo+7Zs0azZkzR3feeadGjRqla665Ru+9916LTzhZLBZt2bJFAwYM0KRJk3TVVVdp5MiRys/P7/C/wcCBA3X33Xfr9OnTHu0PPfSQrr32WmVkZCg+Pl6ffvqp3n77bQ0YMKDZ73G5XFq0aJFiYmI0ffp0jRo1Sjk5OZKkYcOG6e9//7tcLpemTZumuLg4LV26VDabTQEB/M8y0FEWo/FiMgAAgAnwfxEAAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICp/H/XzOcaQ48+7AAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(noise_scale, accuracy_score)\n",
    "plt.xlabel('Scale of Noise')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result: The accuracy significantly dropped as scale of noise increased"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
