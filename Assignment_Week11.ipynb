{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks image recognition - ConvNet\n",
    "\n",
    "1. Add random noise (see below on `size parameter` on [`np.random.normal`](https://numpy.org/doc/stable/reference/random/generated/numpy.random.normal.html)) to the images in training and testing. **Make sure each image gets a different noise feature added to it. Inspect by printing out several images. Note - the `size` parameter should match the data. **\n",
    "2. Compare the `accuracy` of train and val after N epochs for MLNN with and without noise. \n",
    "3. Vary the amount of noise by changing the `scale` parameter in `np.random.normal` by a factor. Use `.1, .5, 1.0, 2.0, 4.0` for the `scale` and keep track of the `accuracy` for training and validation and plot these results.\n",
    "4. Compare these results with the previous week where we used a MultiLayer Perceptron (this week we use a ConvNet). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks - Image Recognition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\kcosm\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv Net\n",
    "Trains a simple convnet on the MNIST dataset.\n",
    "Gets to 99.25% test accuracy after 12 epochs\n",
    "(there is still a lot of margin for parameter tuning).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if backend.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Add noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noise is added here\n",
    "# The max value of the noise should not grossly surpass 1.0\n",
    "noise_train = np.random.normal(0.5, 0.05, (60000, 28, 28, 1))\n",
    "noise_test = np.random.normal(0.5, 0.05, (10000, 28, 28, 1))\n",
    "x_train2 = x_train + noise_train\n",
    "x_test2 = x_test + noise_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7937039777445263\n",
      "0.22592893773982398\n",
      "0.790001239714075\n",
      "0.23102239788898254\n"
     ]
    }
   ],
   "source": [
    "#check the minimun and maximum value of the noise\n",
    "\n",
    "print(np.max(noise_train))\n",
    "print(np.min(noise_train))\n",
    "print(np.max(noise_test))\n",
    "print(np.min(noise_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Compare Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-A. Accuracy without noise = 83.89%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\kcosm\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\kcosm\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Epoch 1/12\n",
      "WARNING:tensorflow:From C:\\Users\\kcosm\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\kcosm\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "469/469 [==============================] - 67s 137ms/step - loss: 2.2815 - accuracy: 0.1424 - val_loss: 2.2540 - val_accuracy: 0.2601\n",
      "Epoch 2/12\n",
      "469/469 [==============================] - 71s 150ms/step - loss: 2.2349 - accuracy: 0.2375 - val_loss: 2.1969 - val_accuracy: 0.4094\n",
      "Epoch 3/12\n",
      "469/469 [==============================] - 64s 136ms/step - loss: 2.1766 - accuracy: 0.3216 - val_loss: 2.1215 - val_accuracy: 0.5204\n",
      "Epoch 4/12\n",
      "469/469 [==============================] - 63s 134ms/step - loss: 2.0958 - accuracy: 0.4020 - val_loss: 2.0188 - val_accuracy: 0.6073\n",
      "Epoch 5/12\n",
      "469/469 [==============================] - 68s 144ms/step - loss: 1.9894 - accuracy: 0.4690 - val_loss: 1.8816 - val_accuracy: 0.6847\n",
      "Epoch 6/12\n",
      "469/469 [==============================] - 65s 139ms/step - loss: 1.8534 - accuracy: 0.5320 - val_loss: 1.7092 - val_accuracy: 0.7397\n",
      "Epoch 7/12\n",
      "469/469 [==============================] - 58s 123ms/step - loss: 1.6922 - accuracy: 0.5810 - val_loss: 1.5123 - val_accuracy: 0.7718\n",
      "Epoch 8/12\n",
      "469/469 [==============================] - 59s 127ms/step - loss: 1.5241 - accuracy: 0.6144 - val_loss: 1.3116 - val_accuracy: 0.7962\n",
      "Epoch 9/12\n",
      "469/469 [==============================] - 68s 145ms/step - loss: 1.3667 - accuracy: 0.6445 - val_loss: 1.1293 - val_accuracy: 0.8099\n",
      "Epoch 10/12\n",
      "469/469 [==============================] - 60s 127ms/step - loss: 1.2290 - accuracy: 0.6694 - val_loss: 0.9780 - val_accuracy: 0.8234\n",
      "Epoch 11/12\n",
      "469/469 [==============================] - 63s 135ms/step - loss: 1.1168 - accuracy: 0.6922 - val_loss: 0.8607 - val_accuracy: 0.8319\n",
      "Epoch 12/12\n",
      "469/469 [==============================] - 58s 124ms/step - loss: 1.0278 - accuracy: 0.7056 - val_loss: 0.7708 - val_accuracy: 0.8389\n",
      "Test loss: 0.7707778215408325\n",
      "Test accuracy: 0.8389000296592712\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-B. Accuracy with noise = 87.22%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "469/469 [==============================] - 62s 131ms/step - loss: 1.2414 - accuracy: 0.5860 - val_loss: 0.7409 - val_accuracy: 0.8406\n",
      "Epoch 2/12\n",
      "469/469 [==============================] - 58s 125ms/step - loss: 1.0687 - accuracy: 0.6628 - val_loss: 0.7181 - val_accuracy: 0.8469\n",
      "Epoch 3/12\n",
      "469/469 [==============================] - 58s 125ms/step - loss: 1.0200 - accuracy: 0.6833 - val_loss: 0.6873 - val_accuracy: 0.8491\n",
      "Epoch 4/12\n",
      "469/469 [==============================] - 57s 121ms/step - loss: 0.9890 - accuracy: 0.6926 - val_loss: 0.6576 - val_accuracy: 0.8518\n",
      "Epoch 5/12\n",
      "469/469 [==============================] - 58s 125ms/step - loss: 0.9613 - accuracy: 0.7024 - val_loss: 0.6308 - val_accuracy: 0.8561\n",
      "Epoch 6/12\n",
      "469/469 [==============================] - 56s 119ms/step - loss: 0.9321 - accuracy: 0.7112 - val_loss: 0.6063 - val_accuracy: 0.8580\n",
      "Epoch 7/12\n",
      "469/469 [==============================] - 58s 123ms/step - loss: 0.9051 - accuracy: 0.7191 - val_loss: 0.5850 - val_accuracy: 0.8608\n",
      "Epoch 8/12\n",
      "469/469 [==============================] - 58s 124ms/step - loss: 0.8856 - accuracy: 0.7260 - val_loss: 0.5658 - val_accuracy: 0.8641\n",
      "Epoch 9/12\n",
      "469/469 [==============================] - 59s 125ms/step - loss: 0.8629 - accuracy: 0.7293 - val_loss: 0.5488 - val_accuracy: 0.8674\n",
      "Epoch 10/12\n",
      "469/469 [==============================] - 57s 122ms/step - loss: 0.8396 - accuracy: 0.7377 - val_loss: 0.5330 - val_accuracy: 0.8686\n",
      "Epoch 11/12\n",
      "469/469 [==============================] - 64s 137ms/step - loss: 0.8250 - accuracy: 0.7397 - val_loss: 0.5189 - val_accuracy: 0.8709\n",
      "Epoch 12/12\n",
      "469/469 [==============================] - 73s 155ms/step - loss: 0.8081 - accuracy: 0.7473 - val_loss: 0.5058 - val_accuracy: 0.8722\n",
      "Test loss: 0.50580894947052\n",
      "Test accuracy: 0.8722000122070312\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train2, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test2, y_test))\n",
    "score = model.evaluate(x_test2, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result: Accuracy increased by 3.33%p due to the noise (Why??)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Vary noises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "469/469 [==============================] - 74s 155ms/step - loss: 0.8023 - accuracy: 0.7506 - val_loss: 0.4999 - val_accuracy: 0.8735\n",
      "Epoch 2/12\n",
      "469/469 [==============================] - 71s 151ms/step - loss: 0.7900 - accuracy: 0.7533 - val_loss: 0.4887 - val_accuracy: 0.8748\n",
      "Epoch 3/12\n",
      "469/469 [==============================] - 65s 138ms/step - loss: 0.7760 - accuracy: 0.7554 - val_loss: 0.4787 - val_accuracy: 0.8762\n",
      "Epoch 4/12\n",
      "469/469 [==============================] - 67s 142ms/step - loss: 0.7639 - accuracy: 0.7599 - val_loss: 0.4700 - val_accuracy: 0.8784\n",
      "Epoch 5/12\n",
      "469/469 [==============================] - 65s 138ms/step - loss: 0.7511 - accuracy: 0.7640 - val_loss: 0.4606 - val_accuracy: 0.8806\n",
      "Epoch 6/12\n",
      "469/469 [==============================] - 66s 142ms/step - loss: 0.7371 - accuracy: 0.7700 - val_loss: 0.4520 - val_accuracy: 0.8807\n",
      "Epoch 7/12\n",
      "469/469 [==============================] - 66s 140ms/step - loss: 0.7262 - accuracy: 0.7734 - val_loss: 0.4439 - val_accuracy: 0.8815\n",
      "Epoch 8/12\n",
      "469/469 [==============================] - 66s 141ms/step - loss: 0.7150 - accuracy: 0.7763 - val_loss: 0.4376 - val_accuracy: 0.8823\n",
      "Epoch 9/12\n",
      "469/469 [==============================] - 66s 140ms/step - loss: 0.7074 - accuracy: 0.7771 - val_loss: 0.4315 - val_accuracy: 0.8840\n",
      "Epoch 10/12\n",
      "469/469 [==============================] - 66s 140ms/step - loss: 0.6981 - accuracy: 0.7821 - val_loss: 0.4251 - val_accuracy: 0.8850\n",
      "Epoch 11/12\n",
      "469/469 [==============================] - 66s 141ms/step - loss: 0.6902 - accuracy: 0.7812 - val_loss: 0.4204 - val_accuracy: 0.8858\n",
      "Epoch 12/12\n",
      "469/469 [==============================] - 67s 142ms/step - loss: 0.6793 - accuracy: 0.7862 - val_loss: 0.4142 - val_accuracy: 0.8865\n",
      "Epoch 1/12\n",
      "469/469 [==============================] - 75s 158ms/step - loss: 0.8465 - accuracy: 0.7260 - val_loss: 0.5413 - val_accuracy: 0.8442\n",
      "Epoch 2/12\n",
      "469/469 [==============================] - 68s 146ms/step - loss: 0.8366 - accuracy: 0.7283 - val_loss: 0.5387 - val_accuracy: 0.8438\n",
      "Epoch 3/12\n",
      "469/469 [==============================] - 68s 145ms/step - loss: 0.8325 - accuracy: 0.7316 - val_loss: 0.5364 - val_accuracy: 0.8438\n",
      "Epoch 4/12\n",
      "469/469 [==============================] - 68s 145ms/step - loss: 0.8308 - accuracy: 0.7316 - val_loss: 0.5332 - val_accuracy: 0.8448\n",
      "Epoch 5/12\n",
      "469/469 [==============================] - 66s 142ms/step - loss: 0.8190 - accuracy: 0.7361 - val_loss: 0.5291 - val_accuracy: 0.8454\n",
      "Epoch 6/12\n",
      "469/469 [==============================] - 73s 156ms/step - loss: 0.8072 - accuracy: 0.7390 - val_loss: 0.5240 - val_accuracy: 0.8472\n",
      "Epoch 7/12\n",
      "469/469 [==============================] - 67s 143ms/step - loss: 0.8071 - accuracy: 0.7383 - val_loss: 0.5210 - val_accuracy: 0.8479\n",
      "Epoch 8/12\n",
      "469/469 [==============================] - 68s 146ms/step - loss: 0.8063 - accuracy: 0.7416 - val_loss: 0.5187 - val_accuracy: 0.8486\n",
      "Epoch 9/12\n",
      "469/469 [==============================] - 68s 144ms/step - loss: 0.8012 - accuracy: 0.7416 - val_loss: 0.5158 - val_accuracy: 0.8490\n",
      "Epoch 10/12\n",
      "469/469 [==============================] - 68s 145ms/step - loss: 0.7926 - accuracy: 0.7442 - val_loss: 0.5138 - val_accuracy: 0.8495\n",
      "Epoch 11/12\n",
      "469/469 [==============================] - 69s 148ms/step - loss: 0.7913 - accuracy: 0.7465 - val_loss: 0.5105 - val_accuracy: 0.8501\n",
      "Epoch 12/12\n",
      "469/469 [==============================] - 67s 142ms/step - loss: 0.7815 - accuracy: 0.7490 - val_loss: 0.5071 - val_accuracy: 0.8526\n",
      "Epoch 1/12\n",
      "469/469 [==============================] - 76s 161ms/step - loss: 1.1708 - accuracy: 0.6137 - val_loss: 0.8573 - val_accuracy: 0.7250\n",
      "Epoch 2/12\n",
      "469/469 [==============================] - 73s 155ms/step - loss: 1.1593 - accuracy: 0.6122 - val_loss: 0.8629 - val_accuracy: 0.7236\n",
      "Epoch 3/12\n",
      "469/469 [==============================] - 73s 156ms/step - loss: 1.1501 - accuracy: 0.6172 - val_loss: 0.8623 - val_accuracy: 0.7262\n",
      "Epoch 4/12\n",
      "469/469 [==============================] - 71s 152ms/step - loss: 1.1553 - accuracy: 0.6156 - val_loss: 0.8598 - val_accuracy: 0.7277\n",
      "Epoch 5/12\n",
      "469/469 [==============================] - 70s 150ms/step - loss: 1.1449 - accuracy: 0.6163 - val_loss: 0.8560 - val_accuracy: 0.7291\n",
      "Epoch 6/12\n",
      "469/469 [==============================] - 72s 153ms/step - loss: 1.1465 - accuracy: 0.6168 - val_loss: 0.8554 - val_accuracy: 0.7283\n",
      "Epoch 7/12\n",
      "469/469 [==============================] - 70s 149ms/step - loss: 1.1419 - accuracy: 0.6188 - val_loss: 0.8550 - val_accuracy: 0.7288\n",
      "Epoch 8/12\n",
      "469/469 [==============================] - 71s 151ms/step - loss: 1.1337 - accuracy: 0.6232 - val_loss: 0.8509 - val_accuracy: 0.7278\n",
      "Epoch 9/12\n",
      "469/469 [==============================] - 72s 154ms/step - loss: 1.1313 - accuracy: 0.6221 - val_loss: 0.8487 - val_accuracy: 0.7288\n",
      "Epoch 10/12\n",
      "469/469 [==============================] - 73s 156ms/step - loss: 1.1251 - accuracy: 0.6244 - val_loss: 0.8462 - val_accuracy: 0.7295\n",
      "Epoch 11/12\n",
      "469/469 [==============================] - 77s 164ms/step - loss: 1.1225 - accuracy: 0.6255 - val_loss: 0.8444 - val_accuracy: 0.7299\n",
      "Epoch 12/12\n",
      "469/469 [==============================] - 73s 155ms/step - loss: 1.1165 - accuracy: 0.6286 - val_loss: 0.8411 - val_accuracy: 0.7312\n",
      "Epoch 1/12\n",
      "469/469 [==============================] - 75s 148ms/step - loss: 1.8616 - accuracy: 0.3892 - val_loss: 1.5972 - val_accuracy: 0.4643\n",
      "Epoch 2/12\n",
      "469/469 [==============================] - 73s 156ms/step - loss: 1.7951 - accuracy: 0.3807 - val_loss: 1.6242 - val_accuracy: 0.4608\n",
      "Epoch 3/12\n",
      "469/469 [==============================] - 68s 144ms/step - loss: 1.7910 - accuracy: 0.3816 - val_loss: 1.6225 - val_accuracy: 0.4639\n",
      "Epoch 4/12\n",
      "469/469 [==============================] - 70s 149ms/step - loss: 1.7834 - accuracy: 0.3857 - val_loss: 1.6175 - val_accuracy: 0.4648\n",
      "Epoch 5/12\n",
      "469/469 [==============================] - 69s 147ms/step - loss: 1.7833 - accuracy: 0.3839 - val_loss: 1.6132 - val_accuracy: 0.4680\n",
      "Epoch 6/12\n",
      "469/469 [==============================] - 68s 145ms/step - loss: 1.7811 - accuracy: 0.3882 - val_loss: 1.6132 - val_accuracy: 0.4679\n",
      "Epoch 7/12\n",
      "469/469 [==============================] - 71s 152ms/step - loss: 1.7796 - accuracy: 0.3868 - val_loss: 1.6120 - val_accuracy: 0.4676\n",
      "Epoch 8/12\n",
      "469/469 [==============================] - 70s 150ms/step - loss: 1.7732 - accuracy: 0.3913 - val_loss: 1.6042 - val_accuracy: 0.4701\n",
      "Epoch 9/12\n",
      "469/469 [==============================] - 67s 143ms/step - loss: 1.7731 - accuracy: 0.3894 - val_loss: 1.6044 - val_accuracy: 0.4691\n",
      "Epoch 10/12\n",
      "469/469 [==============================] - 65s 139ms/step - loss: 1.7710 - accuracy: 0.3887 - val_loss: 1.5991 - val_accuracy: 0.4692\n",
      "Epoch 11/12\n",
      "469/469 [==============================] - 67s 142ms/step - loss: 1.7729 - accuracy: 0.3922 - val_loss: 1.6003 - val_accuracy: 0.4719\n",
      "Epoch 12/12\n",
      "469/469 [==============================] - 67s 142ms/step - loss: 1.7681 - accuracy: 0.3885 - val_loss: 1.5987 - val_accuracy: 0.4730\n",
      "Epoch 1/12\n",
      "469/469 [==============================] - 72s 153ms/step - loss: 2.3196 - accuracy: 0.2137 - val_loss: 2.1555 - val_accuracy: 0.2372\n",
      "Epoch 2/12\n",
      "469/469 [==============================] - 72s 153ms/step - loss: 2.2160 - accuracy: 0.2040 - val_loss: 2.1767 - val_accuracy: 0.2302\n",
      "Epoch 3/12\n",
      "469/469 [==============================] - 69s 147ms/step - loss: 2.2091 - accuracy: 0.2040 - val_loss: 2.1792 - val_accuracy: 0.2276\n",
      "Epoch 4/12\n",
      "469/469 [==============================] - 71s 152ms/step - loss: 2.2084 - accuracy: 0.2011 - val_loss: 2.1794 - val_accuracy: 0.2293\n",
      "Epoch 5/12\n",
      "469/469 [==============================] - 70s 150ms/step - loss: 2.2066 - accuracy: 0.2016 - val_loss: 2.1780 - val_accuracy: 0.2296\n",
      "Epoch 6/12\n",
      "469/469 [==============================] - 70s 148ms/step - loss: 2.2096 - accuracy: 0.2002 - val_loss: 2.1787 - val_accuracy: 0.2298\n",
      "Epoch 7/12\n",
      "469/469 [==============================] - 70s 150ms/step - loss: 2.2042 - accuracy: 0.2006 - val_loss: 2.1760 - val_accuracy: 0.2307\n",
      "Epoch 8/12\n",
      "469/469 [==============================] - 69s 146ms/step - loss: 2.2057 - accuracy: 0.2035 - val_loss: 2.1762 - val_accuracy: 0.2321\n",
      "Epoch 9/12\n",
      "469/469 [==============================] - 73s 156ms/step - loss: 2.2041 - accuracy: 0.1996 - val_loss: 2.1725 - val_accuracy: 0.2333\n",
      "Epoch 10/12\n",
      "469/469 [==============================] - 70s 149ms/step - loss: 2.2042 - accuracy: 0.2012 - val_loss: 2.1733 - val_accuracy: 0.2336\n",
      "Epoch 11/12\n",
      "469/469 [==============================] - 70s 150ms/step - loss: 2.2046 - accuracy: 0.2004 - val_loss: 2.1740 - val_accuracy: 0.2325\n",
      "Epoch 12/12\n",
      "469/469 [==============================] - 72s 154ms/step - loss: 2.2039 - accuracy: 0.2012 - val_loss: 2.1728 - val_accuracy: 0.2337\n"
     ]
    }
   ],
   "source": [
    "accuracy_score = []\n",
    "noise_scale = [.1, .5, 1.0, 2.0, 4.0]\n",
    "\n",
    "#set for loop to see scores for each scale of noise\n",
    "for scale in noise_scale:\n",
    "    \n",
    "    noise_train = np.random.normal(0.5, scale, (60000, 28, 28, 1))\n",
    "    noise_test = np.random.normal(0.5, scale, (10000, 28, 28, 1))\n",
    "    x_train3 = x_train + noise_train\n",
    "    x_test3 = x_test + noise_test\n",
    "    \n",
    "    history3 = model.fit(x_train3, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test3, y_test))\n",
    "    \n",
    "    score3 = model.evaluate(x_test3, y_test, verbose=0)\n",
    "    accuracy = score3[1]\n",
    "    accuracy_score.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8865000009536743, 0.8525999784469604, 0.7311999797821045, 0.4729999899864197, 0.2337000072002411]\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGwCAYAAABVdURTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAx9UlEQVR4nO3de1yUdf7//+cwCGMok4dETEKsPBDaCiSBmbuZeMpkt0+ZW5qlpd08kW4HcltXb+6i7Za2FWyWmqWbfPK0tZnJrudoMxHzQGulFKSjfNQEshVsuH5/+GV+TRxkOA1z8bjfbtcf8+b9vq7X2/femudep7EYhmEIAADAJPy8XQAAAEBDItwAAABTIdwAAABTIdwAAABTIdwAAABTIdwAAABTIdwAAABT8fd2AU2tvLxcJ06cUNu2bWWxWLxdDgAAqAXDMFRSUqIuXbrIz6/mczMtLtycOHFCYWFh3i4DAADUQUFBgbp27VpjnxYXbtq2bSvp0j9OcHCwl6sBAAC1UVxcrLCwMNf3eE1aXLipuBQVHBxMuAEAwMfU5pYSbigGAACmQrgBAACmQrgBAACm4vVwk5aWpoiICNlsNsXExGjXrl019n/55ZfVu3dvtW7dWj179tQbb7zRRJUCAABf4NUbijMyMpScnKy0tDQNGDBAr7zyioYPH67c3Fxdc801lfqnp6crJSVFr776qm666Sbt2bNHDz/8sNq1a6dRo0Z5YQYAAKC5sRiGYXjr4HFxcYqOjlZ6erqrrXfv3kpKSlJqamql/gkJCRowYID+9Kc/udqSk5O1d+9e7d69u1bHLC4ult1uV1FREU9LAQDgIzz5/vbaZamysjJlZ2crMTHRrT0xMVFZWVlVjiktLZXNZnNra926tfbs2aOLFy9WO6a4uNhtAwAA5uW1cHP69Gk5nU6FhIS4tYeEhOjkyZNVjhk6dKhee+01ZWdnyzAM7d27V8uXL9fFixd1+vTpKsekpqbKbre7Nt5ODACAuXn9huKfvozHMIxqX9DzzDPPaPjw4br55pvVqlUrjR49WhMmTJAkWa3WKsekpKSoqKjItRUUFDRo/QAAoHnxWrjp2LGjrFZrpbM0hYWFlc7mVGjdurWWL1+u77//Xl999ZXy8/PVrVs3tW3bVh07dqxyTGBgoOttxI35VmJnuaGPjp7R3/cf10dHz8hZ7rVbmQAAaNG89rRUQECAYmJilJmZqV/+8peu9szMTI0ePbrGsa1atXL9aNaaNWt0xx13XPYXQhvT5kMOzXs3V46iC662ULtNc0dFalhUqNfqAgCgJfLqo+CzZs3SuHHjFBsbq/j4eC1dulT5+fmaMmWKpEuXlI4fP+56l83nn3+uPXv2KC4uTt9++62ef/55HTp0SCtXrvTaHDYfcujRVfv00/M0J4su6NFV+5R+fzQBBwCAJuTVcDNmzBidOXNG8+fPl8PhUFRUlDZt2qTw8HBJksPhUH5+vqu/0+nUc889pyNHjqhVq1b6xS9+oaysLHXr1s0r9TvLDc17N7dSsJEkQ5JF0rx3czUksrOsfpf/oS8AAFB/Xn3PjTc05HtuPjp6RmNf/fdl+7318M2Kv7ZDvY4FAEBL5hPvuTGDwpILl+/kQT8AAFB/hJt66NTWdvlOHvQDAAD1R7iph/4R7RVqt6m6u2ksuvTUVP+I9k1ZFgAALRrhph6sfhbNHRUpSZUCTsXnuaMiuZkYAIAmRLipp2FRoUq/P1qd7e6XnjrbbTwGDgCAF3j1UXCzGBYVqiGRnbUn76wKSy6oU9tLl6I4YwMAQNMj3DQQq5+Fx70BAGgGuCwFAABMhXADAABMhXADAABMhXADAABMhXADAABMhaelWjhnucEj7AAAUyHctGCbDzk0791cOYr+/x/2DLXbNHdUJC8fBAD4LC5LtVCbDzn06Kp9bsFGkk4WXdCjq/Zp8yGHlyoDAKB+CDctkLPc0Lx3c2VU8beKtnnv5spZXlUPAACaN8JNC7Qn72ylMzY/ZkhyFF3QnryzTVcUAAANhHDTAhWWVB9s6tIPAIDmhHDTAnVqa7t8Jw/6AQDQnBBuWqD+Ee0Varepuge+Lbr01FT/iPZNWRYAAA2CcNMCWf0smjsqUpIqBZyKz3NHRfK+GwCATyLctFDDokKVfn+0OtvdLz11ttuUfn8077kBAPgsXuLXgg2LCtWQyM68oRgAYCqEmxbO6mdR/LUdvF0GAAANhstSAADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVLwebtLS0hQRESGbzaaYmBjt2rWrxv6rV6/WjTfeqCuuuEKhoaF68MEHdebMmSaqFgAANHdeDTcZGRlKTk7WnDlzlJOTo4EDB2r48OHKz8+vsv/u3bs1fvx4TZw4UYcPH9bbb7+tTz75RJMmTWriygEAQHPl1XDz/PPPa+LEiZo0aZJ69+6tJUuWKCwsTOnp6VX2//e//61u3bppxowZioiI0C233KLJkydr79691R6jtLRUxcXFbhsAADAvr4WbsrIyZWdnKzEx0a09MTFRWVlZVY5JSEjQN998o02bNskwDJ06dUpr167VyJEjqz1Oamqq7Ha7awsLC2vQeQAAgObFa+Hm9OnTcjqdCgkJcWsPCQnRyZMnqxyTkJCg1atXa8yYMQoICFDnzp115ZVX6sUXX6z2OCkpKSoqKnJtBQUFDToPAADQvHj9hmKLxeL22TCMSm0VcnNzNWPGDP3ud79Tdna2Nm/erLy8PE2ZMqXa/QcGBio4ONhtAwAA5uXvrQN37NhRVqu10lmawsLCSmdzKqSmpmrAgAF6/PHHJUl9+/ZVUFCQBg4cqAULFig0NLTR6wYAAM2b187cBAQEKCYmRpmZmW7tmZmZSkhIqHLM999/Lz8/95KtVqukS2d8AAAAvHpZatasWXrttde0fPlyffbZZ3rssceUn5/vusyUkpKi8ePHu/qPGjVK69evV3p6uo4dO6YPP/xQM2bMUP/+/dWlSxdvTQMAADQjXrssJUljxozRmTNnNH/+fDkcDkVFRWnTpk0KDw+XJDkcDrd33kyYMEElJSV66aWXNHv2bF155ZW67bbbtGjRIm9NAQAANDMWo4VdzykuLpbdbldRURE3FwMA4CM8+f72+tNSAAAADYlwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATMXf2wUATcFZbmhP3lkVllxQp7Y29Y9oL6ufxdtlAQAaAeEGprf5kEPz3s2Vo+iCqy3UbtPcUZEaFhXqxcoAAI2By1Iwtc2HHHp01T63YCNJJ4su6NFV+7T5kMNLlQEAGgvhBqblLDc0791cGVX8raJt3ru5cpZX1QMA4KsINzCtPXlnK52x+TFDkqPogvbknW26ogAAjY5wA9MqLKk+2NSlHwDANxBuYFqd2toatB8AwDcQbmBa/SPaK9RuU3UPfFt06amp/hHtm7IsAEAjI9zAtKx+Fs0dFSlJlQJOxee5oyJ53w0AmAzhBqY2LCpU6fdHq7Pd/dJTZ7tN6fdH854bADAhXuIH0xsWFaohkZ15QzEAtBCEG7QIVj+L4q/t4O0yAABNgMtSAADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVLwebtLS0hQRESGbzaaYmBjt2rWr2r4TJkyQxWKptN1www1NWDEAAGjOvBpuMjIylJycrDlz5ignJ0cDBw7U8OHDlZ+fX2X/F154QQ6Hw7UVFBSoffv2uvvuu5u4cgAA0FxZDMMwvHXwuLg4RUdHKz093dXWu3dvJSUlKTU19bLjN27cqF/96lfKy8tTeHh4rY5ZXFwsu92uoqIiBQcH17l2AADQdDz5/vbamZuysjJlZ2crMTHRrT0xMVFZWVm12seyZct0++231xhsSktLVVxc7LYBAADz8lq4OX36tJxOp0JCQtzaQ0JCdPLkycuOdzgcev/99zVp0qQa+6Wmpsput7u2sLCwetUNAACaN6/fUGyxuP++j2EYldqq8vrrr+vKK69UUlJSjf1SUlJUVFTk2goKCupTLgAAaOa89ttSHTt2lNVqrXSWprCwsNLZnJ8yDEPLly/XuHHjFBAQUGPfwMBABQYG1rteAADgG7x25iYgIEAxMTHKzMx0a8/MzFRCQkKNY3fs2KEvv/xSEydObMwSAQCAD/Lqr4LPmjVL48aNU2xsrOLj47V06VLl5+drypQpki5dUjp+/LjeeOMNt3HLli1TXFycoqKivFE2AABoxrwabsaMGaMzZ85o/vz5cjgcioqK0qZNm1xPPzkcjkrvvCkqKtK6dev0wgsveKNkAADQzHn1PTfewHtuAADwPT7xnhsAAIDGQLgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACm4nG46datm+bPn6/8/PzGqAcAAKBePA43s2fP1t///nd1795dQ4YM0Zo1a1RaWtoYtQEAAHjM43Azffp0ZWdnKzs7W5GRkZoxY4ZCQ0M1bdo07du3rzFqBAAAqDWLYRhGfXZw8eJFpaWl6cknn9TFixcVFRWlmTNn6sEHH5TFYmmoOhtMcXGx7Ha7ioqKFBwc7O1yAABALXjy/V3nG4ovXryo//3f/9Wdd96p2bNnKzY2Vq+99pruuecezZkzR/fdd1+t9pOWlqaIiAjZbDbFxMRo165dNfYvLS3VnDlzFB4ersDAQF177bVavnx5XacBAABMxt/TAfv27dOKFSv01ltvyWq1aty4cVq8eLF69erl6pOYmKhbb731svvKyMhQcnKy0tLSNGDAAL3yyisaPny4cnNzdc0111Q55p577tGpU6e0bNkyXXfddSosLNQPP/zg6TQAAIBJeXxZymq1asiQIZo4caKSkpLUqlWrSn3Onz+vadOmacWKFTXuKy4uTtHR0UpPT3e19e7dW0lJSUpNTa3Uf/Pmzbr33nt17NgxtW/fvlb1lpaWut3wXFxcrLCwMC5LAQDgQxr1stSxY8e0efNm3X333VUGG0kKCgq6bLApKytTdna2EhMT3doTExOVlZVV5Zh33nlHsbGxevbZZ3X11VerR48e+s1vfqP//ve/1R4nNTVVdrvdtYWFhV1mhgAAwJd5HG4KCwv18ccfV2r/+OOPtXfv3lrv5/Tp03I6nQoJCXFrDwkJ0cmTJ6scc+zYMe3evVuHDh3Shg0btGTJEq1du1ZTp06t9jgpKSkqKipybQUFBbWuEQAA+B6Pw83UqVOrDAjHjx+vMWRU56dPVBmGUe1TVuXl5bJYLFq9erX69++vESNG6Pnnn9frr79e7dmbwMBABQcHu20AAMC8PA43ubm5io6OrtTer18/5ebm1no/HTt2lNVqrXSWprCwsNLZnAqhoaG6+uqrZbfbXW29e/eWYRj65ptvan1sAABgXh6Hm8DAQJ06dapSu8PhkL9/7R++CggIUExMjDIzM93aMzMzlZCQUOWYAQMG6MSJE/ruu+9cbZ9//rn8/PzUtWvXWh8bAACYl8fhZsiQIa77WCqcO3dOTz/9tIYMGeLRvmbNmqXXXntNy5cv12effabHHntM+fn5mjJliqRL98uMHz/e1f/Xv/61OnTooAcffFC5ubnauXOnHn/8cT300ENq3bq1p1MBAAAm5PF7bp577jndeuutCg8PV79+/SRJ+/fvV0hIiN58802P9jVmzBidOXNG8+fPl8PhUFRUlDZt2qTw8HBJl84G/fgHOtu0aaPMzExNnz5dsbGx6tChg+655x4tWLDA02kAAACTqtPPL5w/f16rV6/Wp59+qtatW6tv374aO3ZstY+GNyf8/AIAAL7Hk+9vj8/cSJfeY/PII4/UqTgAAIDGVKdwI116aio/P19lZWVu7XfeeWe9iwIAAKgrj8PNsWPH9Mtf/lIHDx6UxWJRxVWtinfTOJ3Ohq0QAADAAx4/LTVz5kxFRETo1KlTuuKKK3T48GHt3LlTsbGx2r59eyOUCAAAUHsen7n56KOPtHXrVl111VXy8/OTn5+fbrnlFqWmpmrGjBnKyclpjDoBAABqxeMzN06nU23atJF06S3DJ06ckCSFh4fryJEjDVsdAACAhzw+cxMVFaUDBw6oe/fuiouL07PPPquAgAAtXbpU3bt3b4waAQAAas3jcPPb3/5W58+flyQtWLBAd9xxhwYOHKgOHTooIyOjwQsEAADwRJ1e4vdTZ8+eVbt27ar9Ne/mhJf4AQDgezz5/vbonpsffvhB/v7+OnTokFt7+/btfSLYAAAA8/Mo3Pj7+ys8PJx32QAAgGbL46elfvvb3yolJUVnz55tjHoAAADqxeMbiv/yl7/oyy+/VJcuXRQeHq6goCC3v+/bt6/BigMAAPCUx+EmKSmpEcoAAABoGA3ytJQv4WkpAAB8T6M9LQUAANDceXxZys/Pr8bHvnmSCgAAeJPH4WbDhg1uny9evKicnBytXLlS8+bNa7DCAAAA6qLB7rn529/+poyMDP39739viN01Gu65AQDA93jlnpu4uDj985//bKjdAQAA1EmDhJv//ve/evHFF9W1a9eG2B0AAECdeXzPzU9/INMwDJWUlOiKK67QqlWrGrQ4AAAAT3kcbhYvXuwWbvz8/HTVVVcpLi5O7dq1a9DiAAAAPOVxuJkwYUIjlAEAANAwPL7nZsWKFXr77bcrtb/99ttauXJlgxQFAABQVx6Hm4ULF6pjx46V2jt16qQ//vGPDVIUAABAXXkcbr7++mtFRERUag8PD1d+fn6DFAUAAFBXHoebTp066cCBA5XaP/30U3Xo0KFBigIAAKgrj8PNvffeqxkzZmjbtm1yOp1yOp3aunWrZs6cqXvvvbcxagQAAKg1j5+WWrBggb7++msNHjxY/v6XhpeXl2v8+PHccwMAALyuzr8t9cUXX2j//v1q3bq1+vTpo/Dw8IaurVHw21IAAPgeT76/PT5zU+H666/X9ddfX9fhAAAAjcLje27+53/+RwsXLqzU/qc//Ul33313gxQFAABQVx6Hmx07dmjkyJGV2ocNG6adO3c2SFEAAAB15XG4+e677xQQEFCpvVWrViouLm6QogAAAOrK43ATFRWljIyMSu1r1qxRZGRkgxQFAABQVx7fUPzMM8/orrvu0tGjR3XbbbdJkv71r3/pb3/7m9auXdvgBQIAAHjC43Bz5513auPGjfrjH/+otWvXqnXr1rrxxhu1detWHq0GAABeV+f33FQ4d+6cVq9erWXLlunTTz+V0+lsqNoaBe+5AQDA93jy/e3xPTcVtm7dqvvvv19dunTRSy+9pBEjRmjv3r113R0AAECD8CjcfPPNN1qwYIG6d++usWPHql27drp48aLWrVunBQsWqF+/fh4XkJaWpoiICNlsNsXExGjXrl3V9t2+fbssFkul7T//+Y/HxwUAAOZU63AzYsQIRUZGKjc3Vy+++KJOnDihF198sV4Hz8jIUHJysubMmaOcnBwNHDhQw4cPV35+fo3jjhw5IofD4dp4UzIAAKhQ63CzZcsWTZo0SfPmzdPIkSNltVrrffDnn39eEydO1KRJk9S7d28tWbJEYWFhSk9Pr3Fcp06d1LlzZ9fWELUAAABzqHW42bVrl0pKShQbG6u4uDi99NJL+r//+786H7isrEzZ2dlKTEx0a09MTFRWVlaNY/v166fQ0FANHjxY27Ztq7FvaWmpiouL3TYAAGBetQ438fHxevXVV+VwODR58mStWbNGV199tcrLy5WZmamSkhKPDnz69Gk5nU6FhIS4tYeEhOjkyZNVjgkNDdXSpUu1bt06rV+/Xj179tTgwYNr/NmH1NRU2e121xYWFuZRnQAAwLfU61HwI0eOaNmyZXrzzTd17tw5DRkyRO+8806txp44cUJXX321srKyFB8f72r/wx/+oDfffLPWNwmPGjVKFoul2uOWlpaqtLTU9bm4uFhhYWE8Cg4AgA9pkkfBJalnz5569tln9c033+itt97yaGzHjh1ltVornaUpLCysdDanJjfffLO++OKLav8eGBio4OBgtw0AAJhXvcJNBavVqqSkpFqftZGkgIAAxcTEKDMz0609MzNTCQkJtd5PTk6OQkNDa90fAACYm8c/v9CQZs2apXHjxik2Nlbx8fFaunSp8vPzNWXKFElSSkqKjh8/rjfeeEOStGTJEnXr1k033HCDysrKtGrVKq1bt07r1q3z5jQAAEAz4tVwM2bMGJ05c0bz58+Xw+FQVFSUNm3apPDwcEmSw+Fwe+dNWVmZfvOb3+j48eNq3bq1brjhBr333nsaMWKEt6YAAACamXr/tpSv4belAADwPU12QzEAAEBzQ7gBAACm4tV7bgCgLpzlhvbknVVhyQV1amtT/4j2svpZvF0WgGaCcAPAp2w+5NC8d3PlKLrgagu12zR3VKSGRfFaCABclgLgQzYfcujRVfvcgo0knSy6oEdX7dPmQw4vVQagOSHcAPAJznJD897NVVWPd1a0zXs3V87yFvUAKIAqEG4A+IQ9eWcrnbH5MUOSo+iC9uSdbbqiADRLhBsAPqGwpPpgU5d+AMyLcAPAJ3Rqa2vQfgDMi3ADwCf0j2ivULtN1T3wbdGlp6b6R7RvyrIANEOEGwA+wepn0dxRkZJUKeBUfJ47KpL33QAg3ADwHcOiQpV+f7Q6290vPXW225R+fzTvuQEgiZf4AfAxw6JCNSSyM28oBlAtwg0An2P1syj+2g7eLgNAM8VlKQAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCqEGwAAYCpeDzdpaWmKiIiQzWZTTEyMdu3aVatxH374ofz9/fWzn/2scQsEAAA+xavhJiMjQ8nJyZozZ45ycnI0cOBADR8+XPn5+TWOKyoq0vjx4zV48OAmqhQAAPgKi2EYhrcOHhcXp+joaKWnp7vaevfuraSkJKWmplY77t5779X1118vq9WqjRs3av/+/dX2LS0tVWlpqetzcXGxwsLCVFRUpODg4AaZBwAAaFzFxcWy2+21+v722pmbsrIyZWdnKzEx0a09MTFRWVlZ1Y5bsWKFjh49qrlz59bqOKmpqbLb7a4tLCysXnUDAIDmzWvh5vTp03I6nQoJCXFrDwkJ0cmTJ6sc88UXX+ipp57S6tWr5e/vX6vjpKSkqKioyLUVFBTUu3YAANB81S4hNCKLxeL22TCMSm2S5HQ69etf/1rz5s1Tjx49ar3/wMBABQYG1rtOAADgG7wWbjp27Cir1VrpLE1hYWGlszmSVFJSor179yonJ0fTpk2TJJWXl8swDPn7+2vLli267bbbmqR2AADQfHntslRAQIBiYmKUmZnp1p6ZmamEhIRK/YODg3Xw4EHt37/ftU2ZMkU9e/bU/v37FRcX11SlAwCAZsyrl6VmzZqlcePGKTY2VvHx8Vq6dKny8/M1ZcoUSZfulzl+/LjeeOMN+fn5KSoqym18p06dZLPZKrUDAICWy6vhZsyYMTpz5ozmz58vh8OhqKgobdq0SeHh4ZIkh8Nx2XfeAAAA/JhX33PjDZ48Jw8AAJoHn3jPDQAAQGMg3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFPxerhJS0tTRESEbDabYmJitGvXrmr77t69WwMGDFCHDh3UunVr9erVS4sXL27CagEAQHPn782DZ2RkKDk5WWlpaRowYIBeeeUVDR8+XLm5ubrmmmsq9Q8KCtK0adPUt29fBQUFaffu3Zo8ebKCgoL0yCOPeGEGAACgubEYhmF46+BxcXGKjo5Wenq6q613795KSkpSampqrfbxq1/9SkFBQXrzzTdr1b+4uFh2u11FRUUKDg6uU90AAKBpefL97bXLUmVlZcrOzlZiYqJbe2JiorKysmq1j5ycHGVlZWnQoEHV9iktLVVxcbHbBgAAzMtr4eb06dNyOp0KCQlxaw8JCdHJkydrHNu1a1cFBgYqNjZWU6dO1aRJk6rtm5qaKrvd7trCwsIapH4AANA8ef2GYovF4vbZMIxKbT+1a9cu7d27V3/961+1ZMkSvfXWW9X2TUlJUVFRkWsrKChokLoBAEDz5LUbijt27Cir1VrpLE1hYWGlszk/FRERIUnq06ePTp06pd///vcaO3ZslX0DAwMVGBjYMEUDAIBmz2tnbgICAhQTE6PMzEy39szMTCUkJNR6P4ZhqLS0tKHLAwAAPsqrj4LPmjVL48aNU2xsrOLj47V06VLl5+drypQpki5dUjp+/LjeeOMNSdLLL7+sa665Rr169ZJ06b03f/7znzV9+nSvzQEAADQvXg03Y8aM0ZkzZzR//nw5HA5FRUVp06ZNCg8PlyQ5HA7l5+e7+peXlyslJUV5eXny9/fXtddeq4ULF2ry5MnemgIAAGhmvPqeG2/gPTcAAPgen3jPDQAAQGMg3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFPx93YBAADAHJzlhvbknVVhyQV1amtT/4j2svpZmrwOwg0AAKi3zYccmvdurhxFF1xtoXab5o6K1LCo0CathctSAACgXjYfcujRVfvcgo0knSy6oEdX7dPmQ44mrYdwAwAA6sxZbmjeu7kyqvhbRdu8d3PlLK+qR+Mg3AAAgDrbk3e20hmbHzMkOYouaE/e2SariXADAADqrLCk+mBTl34NgXADAADqrFNbW4P2awiEGwAAUGf9I9or1G5TdQ98W3Tpqan+Ee2brCbCDQAAqDOrn0VzR0VKUqWAU/F57qjIJn3fDeEGAADUy7CoUKXfH63OdvdLT53tNqXfH93k77nhJX4AAKDehkWFakhkZ95QDAAAzMPqZ1H8tR28XQaXpQAAgLkQbgAAgKkQbgAAgKkQbgAAgKkQbgAAgKkQbgAAgKkQbgAAgKkQbgAAgKkQbgAAgKm0uDcUG4YhSSouLvZyJQAAoLYqvrcrvsdr0uLCTUlJiSQpLCzMy5UAAABPlZSUyG6319jHYtQmAplIeXm5Tpw4obZt28piqfnHvIqLixUWFqaCggIFBwc3UYVNj3maC/M0j5YwR4l5mk1jzdMwDJWUlKhLly7y86v5rpoWd+bGz89PXbt29WhMcHCwqf+HWIF5mgvzNI+WMEeJeZpNY8zzcmdsKnBDMQAAMBXCDQAAMBXCTQ0CAwM1d+5cBQYGeruURsU8zYV5mkdLmKPEPM2mOcyzxd1QDAAAzI0zNwAAwFQINwAAwFQINwAAwFQINwAAwFRafLhJS0tTRESEbDabYmJitGvXrhr779ixQzExMbLZbOrevbv++te/NlGl9ePJPLdv3y6LxVJp+89//tOEFXtu586dGjVqlLp06SKLxaKNGzdedoyvraenc/TVtUxNTdVNN92ktm3bqlOnTkpKStKRI0cuO86X1rMuc/TF9UxPT1ffvn1dL3SLj4/X+++/X+MYX1rHCp7O0xfX8qdSU1NlsViUnJxcYz9vrGeLDjcZGRlKTk7WnDlzlJOTo4EDB2r48OHKz8+vsn9eXp5GjBihgQMHKicnR08//bRmzJihdevWNXHlnvF0nhWOHDkih8Ph2q6//vomqrhuzp8/rxtvvFEvvfRSrfr74np6OscKvraWO3bs0NSpU/Xvf/9bmZmZ+uGHH5SYmKjz589XO8bX1rMuc6zgS+vZtWtXLVy4UHv37tXevXt12223afTo0Tp8+HCV/X1tHSt4Os8KvrSWP/bJJ59o6dKl6tu3b439vLaeRgvWv39/Y8qUKW5tvXr1Mp566qkq+z/xxBNGr1693NomT55s3HzzzY1WY0PwdJ7btm0zJBnffvttE1TXOCQZGzZsqLGPr65nhdrM0QxraRiGUVhYaEgyduzYUW0fX1/P2szRLOvZrl0747XXXqvyb76+jj9W0zx9eS1LSkqM66+/3sjMzDQGDRpkzJw5s9q+3lrPFnvmpqysTNnZ2UpMTHRrT0xMVFZWVpVjPvroo0r9hw4dqr179+rixYuNVmt91GWeFfr166fQ0FANHjxY27Zta8wyvcIX17OufH0ti4qKJEnt27evto+vr2dt5ljBV9fT6XRqzZo1On/+vOLj46vs4+vrKNVunhV8cS2nTp2qkSNH6vbbb79sX2+tZ4sNN6dPn5bT6VRISIhbe0hIiE6ePFnlmJMnT1bZ/4cfftDp06cbrdb6qMs8Q0NDtXTpUq1bt07r169Xz549NXjwYO3cubMpSm4yvrienjLDWhqGoVmzZumWW25RVFRUtf18eT1rO0dfXc+DBw+qTZs2CgwM1JQpU7RhwwZFRkZW2deX19GTefrqWq5Zs0b79u1Tampqrfp7az1b3K+C/5TFYnH7bBhGpbbL9a+qvbnxZJ49e/ZUz549XZ/j4+NVUFCgP//5z7r11lsbtc6m5qvrWVtmWMtp06bpwIED2r1792X7+up61naOvrqePXv21P79+3Xu3DmtW7dODzzwgHbs2FHtF7+vrqMn8/TFtSwoKNDMmTO1ZcsW2Wy2Wo/zxnq22DM3HTt2lNVqrXT2orCwsFLKrNC5c+cq+/v7+6tDhw6NVmt91GWeVbn55pv1xRdfNHR5XuWL69kQfGktp0+frnfeeUfbtm1T165da+zrq+vpyRyr4gvrGRAQoOuuu06xsbFKTU3VjTfeqBdeeKHKvr66jpJn86xKc1/L7OxsFRYWKiYmRv7+/vL399eOHTv0l7/8Rf7+/nI6nZXGeGs9W2y4CQgIUExMjDIzM93aMzMzlZCQUOWY+Pj4Sv23bNmi2NhYtWrVqtFqrY+6zLMqOTk5Cg0NbejyvMoX17Mh+MJaGoahadOmaf369dq6dasiIiIuO8bX1rMuc6yKL6znTxmGodLS0ir/5mvrWJOa5lmV5r6WgwcP1sGDB7V//37XFhsbq/vuu0/79++X1WqtNMZr69motys3c2vWrDFatWplLFu2zMjNzTWSk5ONoKAg46uvvjIMwzCeeuopY9y4ca7+x44dM6644grjscceM3Jzc41ly5YZrVq1MtauXeutKdSKp/NcvHixsWHDBuPzzz83Dh06ZDz11FOGJGPdunXemkKtlJSUGDk5OUZOTo4hyXj++eeNnJwc4+uvvzYMwxzr6ekcfXUtH330UcNutxvbt283HA6Ha/v+++9dfXx9PesyR19cz5SUFGPnzp1GXl6eceDAAePpp582/Pz8jC1bthiG4fvrWMHTefriWlblp09LNZf1bNHhxjAM4+WXXzbCw8ONgIAAIzo62u0xzAceeMAYNGiQW//t27cb/fr1MwICAoxu3boZ6enpTVxx3Xgyz0WLFhnXXnutYbPZjHbt2hm33HKL8d5773mhas9UPFr50+2BBx4wDMMc6+npHH11LauaoyRjxYoVrj6+vp51maMvrudDDz3k+m/PVVddZQwePNj1hW8Yvr+OFTydpy+uZVV+Gm6ay3paDOP/3dkDAABgAi32nhsAAGBOhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsATe7nP/+5kpOTG/04S5cuVVhYmPz8/LRkyZJGPdb27dtlsVh07ty5Rj0OgMsj3ABwU1hYqMmTJ+uaa65RYGCgOnfurKFDh+qjjz7ydmkeKS4u1rRp0/Tkk0/q+PHjeuSRR6rsZ7FYZLPZ9PXXX7u1JyUlacKECbU+XkJCghwOh+x2e33KBtAA/L1dAIDm5a677tLFixe1cuVKde/eXadOndK//vUvnT171tuleSQ/P18XL17UyJEjL/tLyxaLRb/73e+0cuXKOh8vICBAnTt3rvN4AA2HMzcAXM6dO6fdu3dr0aJF+sUvfqHw8HD1799fKSkpGjlypFu/Rx55RCEhIbLZbIqKitI//vEPSdKZM2c0duxYde3aVVdccYX69Omjt956q8bjlpWV6YknntDVV1+toKAgxcXFafv27TWOyc/P1+jRo9WmTRsFBwfrnnvu0alTpyRJr7/+uvr06SNJ6t69uywWi7766qtq9zV9+nStWrVKBw8erLZPaWmpZsyYoU6dOslms+mWW27RJ5984vr7Ty9Lff311xo1apTatWunoKAg3XDDDdq0aZOrf25urkaMGKE2bdooJCRE48aN0+nTp2ucM4DaIdwAcGnTpo3atGmjjRs3qrS0tMo+5eXlGj58uLKysrRq1Srl5uZq4cKFslqtkqQLFy4oJiZG//jHP3To0CE98sgjGjdunD7++ONqj/vggw/qww8/1Jo1a3TgwAHdfffdGjZsmL744osq+xuGoaSkJJ09e1Y7duxQZmamjh49qjFjxkiSxowZo3/+85+SpD179sjhcCgsLKza4yckJOiOO+5QSkpKtX2eeOIJrVu3TitXrtS+fft03XXXaejQodWe0Zo6dapKS0u1c+dOHTx4UIsWLVKbNm0kSQ6HQ4MGDdLPfvYz7d27V5s3b9apU6d0zz33VHt8AB5o9N8dB+BT1q5da7Rr186w2WxGQkKCkZKSYnz66aeuv3/wwQeGn5+fceTIkVrvc8SIEcbs2bNdnwcNGmTMnDnTMAzD+PLLLw2LxWIcP37cbczgwYONlJSUKve3ZcsWw2q1Gvn5+a62w4cPG5KMPXv2GIZhGDk5OYYkIy8vr8baJBkbNmwwDh8+bFitVmPnzp2GYRjG6NGjjQceeMAwDMP47rvvjFatWhmrV692jSsrKzO6dOliPPvss4ZhGMa2bdsMSca3335rGIZh9OnTx/j9739f5TGfeeYZIzEx0a2toKDAkOTRvyuAqnHmBoCbu+66SydOnNA777yjoUOHavv27YqOjtbrr78uSdq/f7+6du2qHj16VDne6XTqD3/4g/r27asOHTqoTZs22rJli/Lz86vsv2/fPhmGoR49erjOHLVp00Y7duzQ0aNHqxzz2WefKSwszO1sTGRkpK688kp99tlndZp3ZGSkxo8fryeffLLS344ePaqLFy9qwIABrrZWrVqpf//+1R5vxowZWrBggQYMGKC5c+fqwIEDrr9lZ2dr27ZtbvPt1auX61gA6ocbigFUYrPZNGTIEA0ZMkS/+93vNGnSJM2dO1cTJkxQ69ataxz73HPPafHixVqyZIn69OmjoKAgJScnq6ysrMr+5eXlslqtys7Odl3aqlBxGeenDMOQxWKpdXttzZs3Tz169NDGjRsr7VdSpX3XdLxJkyZp6NCheu+997Rlyxalpqbqueee0/Tp01VeXq5Ro0Zp0aJFlcZd7uZnAJfHmRsAlxUZGanz589Lkvr27atvvvlGn3/+eZV9d+3apdGjR+v+++/XjTfeqO7du1d774wk9evXT06nU4WFhbruuuvctuqePoqMjFR+fr4KCgpcbbm5uSoqKlLv3r3rPM+wsDBNmzZNTz/9tJxOp6v9uuuuU0BAgHbv3u1qu3jxovbu3Vvj8cLCwjRlyhStX79es2fP1quvvipJio6O1uHDh9WtW7dKcw4KCqpz/QAuIdwAcDlz5oxuu+02rVq1SgcOHFBeXp7efvttPfvssxo9erQkadCgQbr11lt11113KTMzU3l5eXr//fe1efNmSZeCQGZmprKysvTZZ59p8uTJOnnyZLXH7NGjh+677z6NHz9e69evV15enj755BMtWrTI7emiH7v99tvVt29f3Xfffdq3b5/27Nmj8ePHa9CgQYqNja3Xv0FKSopOnDjhuiFZkoKCgvToo4/q8ccf1+bNm5Wbm6uHH35Y33//vSZOnFjlfpKTk/XBBx8oLy9P+/bt09atW11BaOrUqTp79qzGjh2rPXv26NixY9qyZYseeught1AFoG4INwBc2rRpo7i4OC1evFi33nqroqKi9Mwzz+jhhx/WSy+95Oq3bt063XTTTRo7dqwiIyP1xBNPuL6Un3nmGUVHR2vo0KH6+c9/rs6dOyspKanG465YsULjx4/X7Nmz1bNnT9155536+OOPq33CyWKxaOPGjWrXrp1uvfVW3X777erevbsyMjLq/W/Qvn17Pfnkk7pw4YJb+8KFC3XXXXdp3Lhxio6O1pdffqkPPvhA7dq1q3I/TqdTU6dOVe/evTVs2DD17NlTaWlpkqQuXbroww8/lNPp1NChQxUVFaWZM2fKbrfLz4//LAP1ZTEqLiYDAACYAP8XAQAAmArhBgAAmArhBgAAmArhBgAAmArhBgAAmArhBgAAmArhBgAAmArhBgAAmArhBgAAmArhBgAAmArhBgAAmMr/B1ZLpKeixo2HAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(noise_scale, accuracy_score)\n",
    "plt.xlabel('Scale of Noise')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result: The accuracy significantly dropped as scale of noise increased"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compare noises with the result of the previous week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                Scale of Noise :  0.1                   0.5                  1.0                 2.0                  4.0\n",
    "- Accuracy Score Using Multilayer: [0.9778000116348267, 0.9319999814033508, 0.7793999910354614, 0.44780001044273376, 0.22589999437332153]\n",
    "- Accuracy Score Using ConvNet:    [0.8865000009536743, 0.8525999784469604, 0.7311999797821045, 0.4729999899864197, 0.2337000072002411]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result: In lower noises(scale =< 1.0), the accuracy scores of Multilayer were higher; in high noises(scale >= 2.0), the accuracy scores of ConvNet were higher. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
